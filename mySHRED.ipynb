{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"XQE2o_DgkWtg"},"outputs":[],"source":["# !pip install cloud-tpu-client\n","# !pip install torch-xla torch-xla-core\n"]},{"cell_type":"markdown","metadata":{"id":"02yGSI8pdVlq"},"source":["### colab"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1379,"status":"ok","timestamp":1746063385274,"user":{"displayName":"Adriano Racano","userId":"12887391736974890682"},"user_tz":-120},"id":"dNkS7kR1Rxn1","outputId":"d26732f4-8581-4ae2-dae5-c295d8b60a29"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import os\n","colab = os.getcwd() == \"/content\"\n","if colab:\n","    from google.colab import drive\n","    drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WpSjHXp0Hgx1"},"outputs":[],"source":["# drive.flush_and_unmount()  # Smonta Google Drive\n","# drive.mount('/content/drive', force_remount=True)  # Rimonta\n"]},{"cell_type":"markdown","metadata":{"id":"5Ob_XRuhcYLF"},"source":["### import"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8WwwpjjtYxOf"},"outputs":[],"source":["# !mpirun --allow-run-as-root --map-by slot:OVERSUBSCRIBE -np 4 python3 ns_dolfinx.py\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tW6UYjUW1V83"},"outputs":[],"source":["from __future__ import print_function\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1131,"status":"ok","timestamp":1746063386409,"user":{"displayName":"Adriano Racano","userId":"12887391736974890682"},"user_tz":-120},"id":"8Osfwt2EjHdU","outputId":"a87adcf9-b098-4e8f-8648-81057d47990b"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-21-3ac0b30d2ee8>:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n","  import tqdm.autonotebook\n"]}],"source":["import os\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","import sys\n","import copy\n","import tqdm.autonotebook\n","from tqdm import tqdm\n","from scipy.interpolate import RBFInterpolator\n","import pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5idVs1KN1duE"},"outputs":[],"source":["from IPython.display import clear_output as clc\n","plt.style.use(\"default\")\n","%config InlineBackend.figure_format = 'retina'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pZod4ry583zK"},"outputs":[],"source":["import seaborn as sns\n","from matplotlib import colors\n","ice = sns.color_palette(\"icefire\", as_cmap=True).colors\n","col = [ice[i] for i in np.concatenate((np.arange(128,0,-10), np.arange(254,128,-9)))]\n","col.insert(0, \"black\")\n","cmap = colors.LinearSegmentedColormap.from_list(\"\", col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gJMShn29ULUu"},"outputs":[],"source":["def add_zoom(zoom = 1.5, dpi = 100):\n","    plt.gcf().set_figheight(plt.gcf().get_figheight() * zoom)\n","    plt.gcf().set_figwidth(plt.gcf().get_figwidth() * zoom)\n","    plt.gcf().dpi = dpi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8lS_58VbULUv"},"outputs":[],"source":["def scatter_array(arr, label = \"label\", leg = False, zoom = 1, dpi = 100, s = 1, c = None):\n","    if not c==None:\n","        plt.scatter(arr[:, 0], arr[:, 1], label = label, s = s, c = c)\n","    else:\n","        plt.scatter(arr[:, 0], arr[:, 1], label = label, s = s)\n","    # plt.scatter(new_control_points_coords[:, 0], new_control_points_coords[:, 1], c = \"b\", label = \"new control pts\")\n","\n","    add_zoom(zoom, dpi = dpi)\n","    plt.gca().set_aspect(\"equal\")\n","    plt.gca().set_adjustable(\"box\")\n","\n","    if leg:\n","        plt.gca().legend(loc = \"upper right\")\n","    # plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PS-Mn9rKYxOe"},"outputs":[],"source":["if colab:\n","    os.chdir(\"/content/drive/MyDrive/mySHRED\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LZ_rz-U8JfT5"},"outputs":[],"source":["naca0012_data = np.load(\"data/naca0012_data.npz\")\n","naca0012_coords = naca0012_data['naca0012_coords']\n","naca0012_airfoil_coords = naca0012_data['naca0012_airfoil_coords']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Ny_wKZm9cQJ"},"outputs":[],"source":["L = 10\n","H = 4\n","# N_points = 121  # numero di punti per la discretizzazione dell'airfoil\n","chord = 1\n","\n","# Airfoil parameters\n","chord = 1  # Adjust as needed\n","Aoa = 20\n","# N_points = 121\n","# c_x, c_y = 0.2 * L + 0.5 * chord, H / 2\n","x_le, y_le = 0.3 * L, 0.5 * H\n"]},{"cell_type":"markdown","metadata":{"id":"ZiAJPCEOW-TG"},"source":["### Utilities"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kh9z8eXummG9"},"outputs":[],"source":["def generate_airfoil(m=0.02, p=0.4, t=0.12, n_points=100, x_le = 0.0, y_le = 0.0):\n","    \"\"\"\n","    Genera un profilo alare tipo NACA-like con parametri semplificati.\n","\n","    Args:\n","        m: massimo camber (es. 0.02 = 2%)\n","        p: posizione del camber (0-1, frazione della corda)\n","        t: spessore massimo (es. 0.12 = 12%)\n","        n_points: numero di punti (metà superiore)\n","\n","    Returns:\n","        x: array di coordinate x\n","        y_upper: array dell’estradosso\n","        y_lower: array dell’intradosso\n","    \"\"\"\n","\n","    # x = np.linspace(0, 1, n_points)\n","    x = (1 - np.cos(np.linspace(0, 1, int(np.ceil(n_points/2)))*np.pi)) / 2\n","\n","    # Curva camber\n","    yc = np.where(x < p,\n","                  m / p**2 * (2*p*x - x**2),\n","                  m / (1 - p)**2 * ((1 - 2*p) + 2*p*x - x**2))\n","\n","    # Derivata del camber\n","    dyc_dx = np.where(x < p,\n","                      2*m / p**2 * (p - x),\n","                      2*m / (1 - p)**2 * (p - x))\n","    theta = np.arctan(dyc_dx)\n","\n","    # Spessore (classica formula NACA 4-digit)\n","    yt = 5 * t * (0.2969*np.sqrt(x) - 0.1260*x - 0.3516*x**2 + 0.2843*x**3 - 0.1015*x**4)\n","\n","    # Coordinate superiori e inferiori\n","    x_upper = x - yt * np.sin(theta)\n","    y_upper = yc + yt * np.cos(theta)\n","    x_lower = x + yt * np.sin(theta)\n","    y_lower = yc - yt * np.cos(theta)\n","\n","    # Unione dei punti per profilo completo\n","    x_coords = np.concatenate([x_upper[::-1], x_lower[1:]])\n","    y_coords = np.concatenate([y_upper[::-1], y_lower[1:]])\n","\n","    return np.concatenate((x_coords.reshape(-1,1) + x_le, y_coords.reshape(-1,1) + y_le), axis = 1)\n","\n","def generate_airfoil_random(chord = 1, n_points=100, x_le = 0.0, y_le = 0.0):\n","    m = np.random.rand() * 0.05 * chord\n","    p = (np.random.rand() * 0.3 + 0.3) * chord\n","    t = (np.random.rand() * 0.06 + 0.09) * chord\n","\n","    return generate_airfoil(m, p, t, n_points, x_le, y_le)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lwrKFO5Rmtxm"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","import matplotlib.tri as tri\n","import numpy as np\n","\n","def order_polygon(xy_points):\n","    \"\"\"\n","    Orders a set of unordered polygon points into a counterclockwise sequence.\n","    \"\"\"\n","    xy_points = np.array(xy_points, dtype=np.float32)\n","\n","    # Compute the centroid (average of all points)\n","    centroid = np.mean(xy_points, axis=0)\n","\n","    # Compute angles relative to centroid\n","    angles = np.arctan2(xy_points[:, 1] - centroid[1], xy_points[:, 0] - centroid[0])\n","\n","    # Sort points by angle in counterclockwise order\n","    sorted_indices = np.argsort(angles)\n","    ordered_points = xy_points[sorted_indices]\n","\n","    return ordered_points\n","\n","def point_in_obstacle(xy_points, xy_obstacle):\n","    \"\"\"\n","    Determine if points are inside the NACA 0012 airfoil using JAX.\n","    \"\"\"\n","    xy_points = np.array(xy_points, dtype=np.float32)\n","    ordered_xy_obstacle = order_polygon(xy_obstacle)\n","    obstacle_x, obstacle_y = ordered_xy_obstacle[:, 0], ordered_xy_obstacle[:, 1]\n","\n","    x_pts = xy_points[:, 0]\n","    y_pts = xy_points[:, 1]\n","\n","    # Roll the obstacle boundary to get pairs of consecutive points\n","    x1, y1 = obstacle_x, obstacle_y\n","    x2, y2 = np.roll(obstacle_x, shift=-1, axis=0), np.roll(obstacle_y, shift=-1, axis=0)\n","\n","    # Conditions for ray intersection with edges\n","    intersects = np.logical_and(\n","        np.logical_or(y1 <= y_pts[:, None], y2 <= y_pts[:, None]),\n","        np.logical_or(y1 > y_pts[:, None], y2 > y_pts[:, None]),\n","    )\n","\n","    # Compute intersection x-coordinates using vectorized form\n","    denom = (y2 - y1) + 1e-9  # Avoid division by zero\n","    x_intersect = x1 + (y_pts[:, None] - y1) * (x2 - x1) / denom\n","\n","    # Check if x-coordinates of the intersection are greater than x_pts\n","    inside = np.sum(\n","        np.where(np.logical_and(intersects, x_pts[:, None] < x_intersect), 1, 0), axis=1\n","    )\n","\n","    # If count of intersections is odd, point is inside\n","    return inside % 2 == 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mz5ElE5DANe2"},"outputs":[],"source":["def interpolate_coords(coords, control_points, displacements):\n","    rbf = RBFInterpolator(control_points, displacements, neighbors=None, smoothing=0.0, epsilon=None, degree=None)\n","    displacements = rbf(coords[:, :2])\n","    new_coords = coords[:, :2] + displacements\n","    return new_coords"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0lsP4yPYACkg"},"outputs":[],"source":["def get_control_points_and_displacements(airfoil_coords, new_airfoil_coords, x0 = 0.0, y0 = 0.0, x1 = 10.0, y1 = 4.0, each = 2, step_size = 0.05):\n","\n","    N_points = airfoil_coords.shape[0]\n","    # print(N_points)\n","    airfoil_control_points_ids = np.arange(0, N_points, each).tolist()\n","    # print(airfoil_control_points_ids.shape)\n","    # print(airfoil_control_points_ids)\n","    airfoil_control_points = airfoil_coords[airfoil_control_points_ids] # + np.array([x_le, y_le])\n","    new_airfoil_control_points = new_airfoil_coords[airfoil_control_points_ids] # + np.array([x_le, y_le])\n","\n","    airfoil_displacements = np.array(new_airfoil_control_points - airfoil_control_points)\n","\n","    wall1_points = np.concatenate((np.arange(x0, x1, step_size).reshape(-1,1), np.zeros(round(x1/step_size)).reshape(-1,1)), axis = 1)\n","    wall2_points = np.concatenate((x1 * np.ones(round(y1/step_size)).reshape(-1,1), np.arange(y0, y1, step_size).reshape(-1,1)), axis = 1)\n","    wall3_points = np.concatenate((np.arange(x1, x0, -step_size).reshape(-1,1), y1 * np.ones(round(x1/step_size)).reshape(-1,1)), axis = 1)\n","    wall4_points = np.concatenate((np.zeros(round(y1/step_size)).reshape(-1,1), np.arange(y1, y0, -step_size).reshape(-1,1)), axis = 1)\n","\n","    control_points = np.concatenate((airfoil_control_points, wall1_points, wall2_points, wall3_points, wall4_points), axis = 0)\n","    displacements = np.concatenate((airfoil_displacements, np.zeros((wall1_points.shape[0] + wall2_points.shape[0] + wall3_points.shape[0] + wall4_points.shape[0], 2))), axis = 0)\n","\n","    return control_points, displacements\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s7M98DTI9R9i"},"outputs":[],"source":["def update_coords_and_triang(params, coords = naca0012_coords, airfoil_coords = naca0012_airfoil_coords):\n","\n","    N_points = airfoil_coords.shape[0]\n","    new_airfoil_coords = generate_airfoil(params[0].item(), params[1].item(), params[2].item(), n_points = N_points, x_le = x_le, y_le = y_le)\n","    control_points, displacements = get_control_points_and_displacements(airfoil_coords, new_airfoil_coords, x0 = 0.0, y0 = 0.0, x1 = L, y1 = H, each = 2, step_size = 0.05)\n","    coords = interpolate_coords(coords, control_points, displacements)\n","    x, y = coords[:, 0], coords[:, 1]\n","    triang = tri.Triangulation(x, y)\n","    x_tri = x[triang.triangles].mean(axis=1)\n","    y_tri = y[triang.triangles].mean(axis=1)\n","    mask = point_in_obstacle(np.vstack([x_tri, y_tri]).transpose(), [(x,y) for x,y in list(zip(new_airfoil_coords[:, 0], new_airfoil_coords[:, 1]))])\n","    triang.set_mask(mask)\n","\n","    return coords, triang"]},{"cell_type":"markdown","metadata":{"id":"SJr_w_YuA7Nl"},"source":["# SHRED-ROM"]},{"cell_type":"markdown","metadata":{"id":"NixfVmQJ8BBh"},"source":["### Positional encoding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IOA9QhwjjjwJ"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v2jzjRfP8BBh"},"outputs":[],"source":["# train_trajectories = len(idx_train)\n","# train_trajectories"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XC5OJSXb8BBh"},"outputs":[],"source":["# sensors_coords_new = torch.from_numpy(sensors_coords_new)\n","# XY = torch.from_numpy(XY)\n","# Vxtrain = torch.from_numpy(Vxtrain)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OwD41Ij28BBh"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","\n","# --------------------------------------------------\n","# 1. Definizione della funzione di Fourier Positional Encoding\n","# --------------------------------------------------\n","def fourier_encode(x, B):\n","    \"\"\"\n","    Applica il positional encoding Fourier alle coordinate.\n","\n","    Parametri:\n","      - x: tensor di shape (n, d) (ad esempio, coordinate spaziali)\n","      - B: tensor di shape (d, D) contenente le frequenze.\n","\n","    Restituisce:\n","      - encoding: tensor di shape (n, 2*D) ottenuto concatenando sin(xB) e cos(xB).\n","    \"\"\"\n","    # Proiezione: x @ B produce un tensore di shape (n, D)\n","    x_proj = 2 * torch.pi * x @ B\n","    return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n","\n","# --------------------------------------------------\n","# 2. Setup dei parametri e degli input\n","# --------------------------------------------------\n","d = 2   # dimensione originale delle coordinate (x, y)\n","D = 16  # dimensione scelta per la proiezione (puoi variare questo parametro)\n","\n","# Matrice di frequenze per il Fourier encoding (può essere fissata oppure resa learnable)\n","B = torch.randn(d, D).to(device)\n","\n","# # --------------------------------------------------\n","# # 3. Calcolo degli encoding Fourier per i nodi e per i sensori\n","# # --------------------------------------------------\n","# # Calcolo dell'encoding per i sensori: shape (nsensors, 2*D)\n","# sensor_encodings = fourier_encode(sensors_coords_new, B)  # comune a tutte le traiettorie\n","\n","# # Calcolo dell'encoding per i nodi per tutte le traiettorie.\n","# # Risultato atteso: (ntraj, nvelocity, 2*D)\n","# # Possiamo calcolarlo in modo vettorizzato:\n","# node_encodings_train = fourier_encode(XY[idx_train].view(-1, d), B)\n","# node_encodings_train = node_encodings_train.view(len(idx_train), nvelocity, 2 * D)\n","\n","# node_encodings_valid = fourier_encode(XY[idx_valid].view(-1, d), B)\n","# node_encodings_valid = node_encodings_valid.view(len(idx_valid), nvelocity, 2 * D)\n","\n","# node_encodings_test = fourier_encode(XY[idx_test].view(-1, d), B)\n","# node_encodings_test = node_encodings_test.view(len(idx_test), nvelocity, 2 * D)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u8bTlGUD8BBh"},"outputs":[],"source":["# # --------------------------------------------------\n","# # 4. Calcolo dei pesi di similarità e interpolazione\n","# # --------------------------------------------------\n","# # Per ogni traiettoria, calcoliamo la similarità fra i sensori e i nodi.\n","# # Usiamo broadcasting per ottenere in una sola operazione:\n","# #\n","# #   sensor_encodings: (nsensors, 2*D)\n","# #   node_encodings: (ntraj, nvelocity, 2*D)\n","# #\n","# # Vogliamo ottenere similarity: (ntraj, nsensors, nvelocity)\n","# # facendo, per ogni traiettoria i e per ogni sensore j,\n","# #   similarity[i,j] = sensor_encodings[j] · node_encodings[i].T\n","# sensor_encodings_expanded = sensor_encodings.unsqueeze(0)  # shape: (1, nsensors, 2*D)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xhL5Op0c8BBh"},"outputs":[],"source":["# # Trasponiamo l'encoding dei nodi per il prodotto scalare:\n","# node_encodings_t = node_encodings_train  # shape: (ntraj, nvelocity, 2*D)\n","# similarity = torch.matmul(sensor_encodings_expanded, node_encodings_t.transpose(1,2))\n","# # similarity: (ntraj, nsensors, nvelocity)\n","\n","# # Otteniamo i pesi (softmax sul nodo-dimensione, ovvero dim=2)\n","# weights = F.softmax(similarity, dim=2)  # shape: (ntraj, nsensors, nvelocity)\n","\n","# # Ora, per ogni traiettoria e per ogni timestep, eseguiamo la media pesata dei valori dei nodi.\n","# # Vxtrain ha shape: (ntraj, ntimes, nvelocity)\n","# # Per eseguire la moltiplicazione, trasponiamo weights in modo che abbiano shape (ntraj, nvelocity, nsensors)\n","# weights_t = weights.transpose(1,2)  # shape: (ntraj, nvelocity, nsensors)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"az4AjhVz8BBh"},"outputs":[],"source":["\n","# # Reshape Vxtrain per includere una dimensione batch 3D: (ntraj*ntimes, 1, nvelocity)\n","# Vxtrain_reshaped = Vxtrain.view(-1, nvelocity).unsqueeze(1)\n","\n","# # Replichiamo i pesi per ogni timestep all'interno della traiettoria:\n","# # weights_t ha shape: (ntraj, nvelocity, nsensors)\n","# # Ripetiamo ogni matrice di pesi ntimes volte lungo l'asse batch:\n","# weights_expanded = weights_t.repeat_interleave(ntimes, dim=0)  # shape: (ntraj*ntimes, nvelocity, nsensors)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FblGl7gY8BBh"},"outputs":[],"source":["# # Ora possiamo fare la moltiplicazione batch-matrix:\n","# Vx_interp_flat = torch.bmm(Vxtrain_reshaped, weights_expanded)  # shape: (ntraj*ntimes, 1, nsensors)\n","# # Rimuoviamo la dimensione 1 e rimodelliamo:\n","# sensors_data_train = Vx_interp_flat.squeeze(1).view(train_trajectories, ntimes, nsensors)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ghvXYVlq8BBh"},"outputs":[],"source":["# # ad ogni step:\n","# # - genero sensor_coords_new\n","# sensor_encodings_expanded = fourier_encode(sensors_coords_new, B).unsqueeze(0)  # shape: (1, nsensors, 2*D)\n","\n","# # - per train, valid e test:\n","# similarity = torch.matmul(sensor_encodings_expanded, node_encodings_t.transpose(1,2))\n","# weights_t = F.softmax(similarity, dim=2).transpose(1,2)  # shape: (ntraj, nvelocity, nsensors)\n","# weights_expanded = weights_t.repeat_interleave(ntimes, dim=0)  # shape: (ntraj*ntimes, nvelocity, nsensors)\n","# sensors_data_flat = torch.bmm(Vxtrain_reshaped, weights_expanded)  # shape: (ntraj*ntimes, 1, nsensors)\n","# sensors_data = Vx_interp_flat.squeeze(1).view(train_trajectories, ntimes, nsensors)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qkcoS0LwFzh3"},"outputs":[],"source":["# def generate_sensor_data(sensors_coords_new, B):\n","\n","    # sensor_encodings_expanded = fourier_encode(sensors_coords_new, B).unsqueeze(0)  # shape: (1, nsensors, 2*D)\n","\n","    # # - per train, valid e test:\n","    # similarity = torch.matmul(sensor_encodings_expanded, node_encodings_t.transpose(1,2))\n","    # weights_t = F.softmax(similarity, dim=2).transpose(1,2)  # shape: (ntraj, nvelocity, nsensors)\n","    # weights_expanded = weights_t.repeat_interleave(ntimes, dim=0)  # shape: (ntraj*ntimes, nvelocity, nsensors)\n","    # sensors_data_flat = torch.bmm(Vxtrain_reshaped, weights_expanded)  # shape: (ntraj*ntimes, 1, nsensors)\n","    # sensors_data = Vx_interp_flat.squeeze(1).view(train_trajectories, ntimes, nsensors)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cOBYsUVp8BBh"},"outputs":[],"source":["# scatter_array(naca0012_coords, s = 0.1)\n","# scatter_array(sensors_coords_new, s = 50)\n","# add_zoom()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A1_ZYK9-8BBh"},"outputs":[],"source":["# # TRAJECTORY WITH SENSORS (PLOT)\n","# import matplotlib as mpl\n","\n","# def trajectory_with_sensors(vt, params_geo, sensors_coordinates, sensors_values, title = None):\n","#     \"\"\"\n","#     Velocity trajectory with sensors\n","#     Input: velocity trajectory with dimension (ntimes, nvelocity), geometric parameters and and the selected sensor indices\n","#     \"\"\"\n","#     # redefine plot_v on new triang\n","#     coords, triang = update_coords_and_triang(params_geo)\n","#     norm = mpl.colors.Normalize(vmin = vt.min().item(), vmax = vt.max().item())\n","#     def plot_v(v, triang = triang):\n","#         plt.tricontourf(triang, v, cmap = cmap, levels = 200, norm = norm)\n","#         plt.gca().set_aspect(\"equal\")\n","#         add_zoom(zoom = 1.3)\n","\n","#     # sensors_coordinates = coords[idx_sensors, :2]\n","#     nsensors = sensors_coordinates.shape[0]\n","\n","#     for i in range(vt.shape[0]):\n","#         plt.figure(figsize=(10,10))\n","#         plot_v(vt[i])\n","#         for k in np.arange(nsensors):\n","#             plt.scatter(sensors_coordinates[k, 0], sensors_coordinates[k, 1], c = sensors_values[i, k],\n","#                         facecolors='none',   # interno trasparente\n","#                         edgecolors='white',\n","#                         marker = 'o', norm = norm, s = 100, cmap = cmap) # , mec = 'black', ms = 8, mew = 1.5)\n","#         plt.xlim((-0.1,10.1))\n","#         plt.title(title)\n","#         plt.axis('off')\n","#         display(plt.gcf())\n","#         plt.close()\n","#         clc(wait=True)\n","\n","# whichtrajectory = 3\n","# whichtimes = np.arange(0, 200, 10)\n","\n","# trajectory_with_sensors(Vxtrain[whichtrajectory, whichtimes],\n","#                         MUtrain[whichtrajectory, 0, 2:],\n","#                         sensors_coordinates=sensors_coords.detach().numpy(),\n","#                         sensors_values= sensors_data_train.detach().numpy()[whichtrajectory, whichtimes],\n","#                         title = \"Velocity trajectory with sensors\")"]},{"cell_type":"markdown","metadata":{"id":"ugYJ5O9lwUI2"},"source":["### Sensor interpolation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PbHNAVQel9pb"},"outputs":[],"source":["class SensorDataInterpolator(torch.nn.Module):\n","    def __init__(self, B, device = device):\n","        \"\"\"\n","        XY: torch.Tensor di shape (ntraj, nvelocity, 2) -> coordinate dei nodi per traiettoria\n","        Vxtrain: torch.Tensor di shape (ntraj, ntimes, nvelocity) -> valori sui nodi (statici nel tempo)\n","        B: torch.Tensor di shape (2, D) -> matrice di frequenze per il Fourier encoding\n","        \"\"\"\n","        super().__init__()\n","        self.B = B\n","        self.device = device\n","\n","    def forward(self, sensors_coords, Vxtrain, node_encodings):\n","        \"\"\"\n","        sensors_coords: torch.Tensor di shape (nsensors, 2  D) (trainable)\n","\n","        Restituisce:\n","           sensor_data: tensor di shape (ntraj, ntimes, nsensors) ottenuto come interpolazione differenziabile\n","           dei valori Vxtrain nei nuovi punti dati dai sensors_coords_encoded.\n","        \"\"\"\n","\n","        ntraj, nvelocity, ntimes = Vxtrain.shape\n","\n","        nsensors = sensors_coords.shape[0]\n","        # Calcola l'encoding dei sensori\n","        sensor_encodings = fourier_encode(sensors_coords, self.B).to(self.device)  # shape: (nsensors, 2*D)\n","        # node_encodings: (ntraj, nvelocity, 2*D); vogliamo il prodotto scalare tra\n","        # ogni sensore ed ogni nodo per ogni traiettoria.\n","        # Risulta una similarità di shape: (ntraj, nsensors, nvelocity)\n","\n","        # nsensors = sensor_encodings.shape[0]\n","\n","        sensor_encodings_expanded = sensor_encodings.unsqueeze(0)  # (1, nsensors, 2*D)\n","        similarity = torch.matmul(sensor_encodings_expanded, node_encodings.transpose(1,2)).to(self.device)\n","\n","        # Softmax lungo l'asse dei nodi per ottenere i pesi\n","        weights = F.softmax(similarity, dim=2).to(self.device)  # shape: (ntraj, nsensors, nvelocity)\n","        # Per eseguire la somma pesata sui valori:\n","        # Vxtrain: (ntraj, ntimes, nvelocity)\n","        # Per la moltiplicazione batch, bisogna trasporre i pesi: (ntraj, nvelocity, nsensors)\n","        weights_t = weights.transpose(1,2)  # (ntraj, nvelocity, nsensors)\n","\n","        sensor_vals = torch.matmul(Vxtrain, weights_t).to(self.device)\n","\n","        return sensor_vals"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0jXWPIT0iC0J"},"outputs":[],"source":["class ReflectWithGradFlip(torch.autograd.Function):\n","    @staticmethod\n","    def forward(ctx, input, L, H):\n","        \"\"\"\n","        input: tensor di shape (n, 2), coordinate dei sensori.\n","        L, H: valori scalari (float) dei limiti per x ed y.\n","        \"\"\"\n","        # Salviamo l'input in ctx per poterlo usare in backward.\n","        ctx.save_for_backward(input)\n","        ctx.L = L\n","        ctx.H = H\n","\n","        # Calcoliamo il valore riflesso per x e y.\n","        # Usiamo la formula: r(x) = L - | L - (x mod (2L)) |\n","        x = input[:, 0]\n","        y = input[:, 1]\n","        # Calcoliamo \"modulo\" con torch.remainder\n","        r_x = L - torch.abs(L - torch.remainder(x, 2 * L))\n","        r_y = H - torch.abs(H - torch.remainder(y, 2 * H))\n","        output = torch.stack([r_x, r_y], dim=1)\n","        return output\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        # Recupera l'input originale\n","        input, = ctx.saved_tensors\n","        L = ctx.L\n","        H = ctx.H\n","\n","        # Inizializza il gradiente per input con quello in grad_output\n","        grad_input = grad_output.clone()\n","\n","        # Definisci maschere per le coordinate fuori dai limiti:\n","        mask_x = (input[:, 0] < 0) | (input[:, 0] > L)\n","        mask_y = (input[:, 1] < 0) | (input[:, 1] > H)\n","        # Inverte il segno del gradiente nelle coordinate fuori dai limiti:\n","        grad_input[:, 0] = torch.where(mask_x, -grad_input[:, 0], grad_input[:, 0])\n","        grad_input[:, 1] = torch.where(mask_y, -grad_input[:, 1], grad_input[:, 1])\n","        # Non generiamo gradiente per L o H (None)\n","        return grad_input, None, None\n","\n","def reflect_with_grad_flip(x, L, H):\n","    \"\"\"\n","    Funzione wrapper per applicare la reflection con inversione dei gradienti\n","    per le coordinate fuori dai limiti.\n","    x: tensor di shape (n, 2)\n","    L, H: limiti (float)\n","    \"\"\"\n","    return ReflectWithGradFlip.apply(x, L, H)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2uAKzPSRWKUD"},"outputs":[],"source":["class GateGradient(torch.autograd.Function):\n","    @staticmethod\n","    def forward(ctx, x, flag):\n","        \"\"\"\n","        x: input tensor\n","        flag: scalare (0.0 oppure 1.0); in forward è ignorato, in backward regola il gradiente\n","        \"\"\"\n","        ctx.flag = flag\n","        return x\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        # In fase backward moltiplica il gradiente per il flag.\n","        return grad_output * ctx.flag, None\n","\n","def gate_gradient(x, flag):\n","    return GateGradient.apply(x, flag)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j7R8j4glTcwQ"},"outputs":[],"source":["# import torch\n","# import torch.nn as nn\n","# import torch.nn.functional as F\n","\n","# class FourierDecoder(nn.Module):\n","#     def __init__(self, encoding_dim, output_dim, hidden_dim=128):\n","#         super(FourierDecoder, self).__init__()\n","#         self.fc1 = nn.Linear(encoding_dim, hidden_dim)\n","#         self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n","#         self.fc3 = nn.Linear(hidden_dim, output_dim)\n","\n","#     def forward(self, z):\n","#         x = F.relu(self.fc1(z))\n","#         x = F.relu(self.fc2(x))\n","#         return self.fc3(x)\n","# n_samples = 10000    # numero di punti\n","# fourier_dim = D     # dimensione encoding per ciascuna coordinata\n","\n","# # 1. Genera punti casuali in [0, L] x [0, H]\n","# x = torch.empty(n_samples, 2)\n","# x[:, 0] = torch.rand(n_samples) * L\n","# x[:, 1] = torch.rand(n_samples) * H\n","\n","# z = fourier_encode(x, B.cpu())  # (n_samples, 2*D)\n","# decoder = FourierDecoder(encoding_dim=z.shape[-1], output_dim=2)\n","# optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n","# loss_fn = nn.MSELoss()\n","\n","# for epoch in range(4000):\n","#     x_pred = decoder(z)\n","#     loss = loss_fn(x_pred, x)\n","#     optimizer.zero_grad()\n","#     loss.backward()\n","#     optimizer.step()\n","#     if epoch % 100 == 0:\n","#         print(f\"Epoch {epoch}, Loss: {loss.item():.6f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"8d3yX9zMowmN"},"source":["### Pre-training\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HhalC_98owmO"},"outputs":[],"source":["# !pip install cloud-tpu-client\n","# !pip install torch-xla torch-xla-core\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Zd0TURKowmO"},"outputs":[],"source":["import torch\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d1ZoQMHYowmO"},"outputs":[],"source":["from copy import deepcopy\n","from IPython.display import clear_output as clc\n","from utils.processdata import mse, mre, num2p\n","\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h6HMG8e6owmP"},"outputs":[],"source":["import importlib\n","import utils.models\n","import utils.processdata\n","importlib.reload(utils.models)\n","importlib.reload(utils.processdata)\n","import utils.models\n","import utils.processdata\n","from utils.models import SHRED, SHREDagnostic, SHREDagnosticAttention, fit_sensors_coords\n","from utils.processdata import Padding, TimeSeriesDataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q9zjZv_QrLLx"},"outputs":[],"source":["data = np.load(\"data/data.npz\")\n","\n","Vxtrain = torch.from_numpy(data[\"Vxtrain\"])\n","Vytrain = torch.from_numpy(data[\"Vytrain\"])\n","Vxvalid = torch.from_numpy(data[\"Vxvalid\"])\n","Vyvalid = torch.from_numpy(data[\"Vyvalid\"])\n","Vxtest = torch.from_numpy(data[\"Vxtest\"])\n","Vytest = torch.from_numpy(data[\"Vytest\"])\n","XY = torch.from_numpy(data[\"XY\"])\n","\n","Wx = torch.from_numpy(data[\"Wx\"])\n","Wy = torch.from_numpy(data[\"Wy\"])\n","\n","Vxtrain_POD = torch.from_numpy(data[\"Vxtrain_POD\"])\n","Vxvalid_POD = torch.from_numpy(data[\"Vxvalid_POD\"])\n","Vxtest_POD = torch.from_numpy(data[\"Vxtest_POD\"])\n","\n","Vytrain_POD = torch.from_numpy(data[\"Vytrain_POD\"])\n","Vyvalid_POD = torch.from_numpy(data[\"Vyvalid_POD\"])\n","Vytest_POD = torch.from_numpy(data[\"Vytest_POD\"])\n","\n","MUtrain = torch.from_numpy(data[\"MUtrain\"])\n","MUvalid = torch.from_numpy(data[\"MUvalid\"])\n","MUtest = torch.from_numpy(data[\"MUtest\"])\n","\n","idx_train = torch.from_numpy(data[\"idx_train\"])\n","idx_valid = torch.from_numpy(data[\"idx_valid\"])\n","idx_test = torch.from_numpy(data[\"idx_test\"])\n","\n","from sklearn.preprocessing import MinMaxScaler\n","with open('data/scalerVx.pkl', 'rb') as f:\n","    scalerVx = pickle.load(f)\n","with open('data/scalerVy.pkl', 'rb') as f:\n","    scalerVy = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y7N45ghBowmQ"},"outputs":[],"source":["# Vxtrain = torch.from_numpy(Vxtrain)\n","# Vytrain = torch.from_numpy(Vytrain)\n","# Vxvalid = torch.from_numpy(Vxvalid)\n","# Vyvalid = torch.from_numpy(Vyvalid)\n","# Vxtest = torch.from_numpy(Vxtest)\n","# Vytest = torch.from_numpy(Vytest)\n","# XY = torch.from_numpy(XY)\n","\n","# Wx = torch.from_numpy(Wx)\n","# Wy = torch.from_numpy(Wy)\n","\n","# Vxtrain_POD = torch.from_numpy(Vxtrain_POD)\n","# Vxvalid_POD = torch.from_numpy(Vxvalid_POD)\n","# Vxtest_POD = torch.from_numpy(Vxtest_POD)\n","\n","# Vytrain_POD = torch.from_numpy(Vytrain_POD)\n","# Vyvalid_POD = torch.from_numpy(Vyvalid_POD)\n","# Vytest_POD = torch.from_numpy(Vytest_POD)\n","\n","# MUtrain = torch.from_numpy(MUtrain)\n","# MUvalid = torch.from_numpy(MUvalid)\n","# MUtest = torch.from_numpy(MUtest)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y8-VzIFypq6d"},"outputs":[],"source":["# np.save(\"data/Vxtrain.npy\", Vxtrain.numpy())\n","# np.save(\"data/Vytrain.npy\", Vytrain.numpy())\n","# np.save(\"data/Vxvalid.npy\", Vxvalid.numpy())\n","# np.save(\"data/Vxtrain.npy\", Vxtrain.numpy())\n","# np.save(\"data/Vyvalid.npy\", Vyvalid.numpy())\n","# np.save(\"data/Vxtest.npy\", Vxtest.numpy())\n","# np.save(\"data/XY.npy\", XY.numpy())\n","\n","\n","# np.save(\"data/Wx.npy\", Wx.numpy())\n","# np.save(\"data/Wy.npy\", Wy.numpy())\n","\n","# np.save(\"data/Vxtrain_POD.npy\", Vxtrain_POD.numpy())\n","# np.save(\"data/Vxvalid_POD.npy\", Vxvalid_POD.numpy())\n","# np.save(\"data/Vxtest_POD.npy\", Vxtest_POD.numpy())\n","\n","# np.save(\"data/Vytrain_POD.npy\", Vytrain_POD.numpy())\n","# np.save(\"data/Vyvalid_POD.npy\", Vyvalid_POD.numpy())\n","# np.save(\"data/Vytest_POD.npy\", Vytest_POD.numpy())\n","\n","# np.save(\"data/MUtrain.npy\", MUtrain.numpy())\n","# np.save(\"data/MUvalid.npy\", MUvalid.numpy())\n","# np.save(\"data/MUtest.npy\", MUtest.numpy())\n","\n","# np.save(\"data/idx_train.npy\", idx_train.numpy())\n","# np.save(\"data/idx_valid.npy\", idx_valid.numpy())\n","# np.save(\"data/idx_test.npy\", idx_test.numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tfc3axrrowmQ"},"outputs":[],"source":["# Assume mesh_coords is an array of shape (nvelocity, coord_dim) with node coordinates\n","# and idx_sensors is already defined (indices of selected sensors)\n","coord_dim = 2  # e.g. 2 for 2D\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","lag = 50\n","kvelocity = Vxtrain_POD.size(2) * 2\n","_, ntimes, nvelocity = Vxtrain.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mh18V74FowmQ"},"outputs":[],"source":["ntrain = len(idx_train) # number of training trajectories\n","nvalid = len(idx_valid)\n","ntest = len(idx_test)\n","\n","nsensors = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UmxTXUJBowmR"},"outputs":[],"source":["# Dataset su RAM\n","\n","class SensorFieldDataset(Dataset):\n","    def __init__(self, hist, sensor_coords, targets):\n","        self.hist = hist\n","        self.sensor_coords = sensor_coords\n","        self.targets = targets\n","    def __len__(self):\n","        return self.hist.size(0)\n","    def __getitem__(self, idx):\n","        return (\n","            self.hist[idx],\n","            self.sensor_coords[idx],\n","            self.targets[idx]\n","        )\n","\n","# # Load training dataset\n","# train_hist = torch.load('data/train_hist.pt').float().to(device)\n","# sensor_coords_exp = torch.load('data/sensor_coords_exp.pt').float().to(device)\n","# train_out = torch.load('data/train_out.pt').float().to(device)\n","\n","# Generate training dataset\n","n_sensors_choices_per_trajectory = 5\n","# sensors_data_train = torch.zeros((n_sensors_choices_per_trajectory * ntrain, ntimes, nsensors))\n","train_hist = torch.zeros((n_sensors_choices_per_trajectory * ntrain * ntimes, nsensors, lag)).to(device)\n","train_out = torch.zeros((n_sensors_choices_per_trajectory * ntrain * ntimes, kvelocity + 1)).to(device)\n","sensor_coords_exp = torch.zeros((n_sensors_choices_per_trajectory * ntrain * ntimes, nsensors, coord_dim)).to(device)\n","for i in range(n_sensors_choices_per_trajectory):\n","    sensors_idx_train = np.stack([\n","        np.random.choice(nvelocity, nsensors, replace=False)\n","        for _ in range(ntrain)\n","    ], axis=0)    # (n_sensors_choices_per_trajectory * ntrain, nsensors)\n","\n","    # sensors_idx_train = indices[idx_train]       # (ntrain,5)\n","    traj_idx_train    = np.arange(ntrain)[:, None, None]   # (ntrain,1,1)\n","    time_idx          = np.arange(ntimes)[None, :, None]   # (1,201,1)\n","    # sensors_idx_train = sensors_idx_train[:, None, :]      # (ntrain,1,5)\n","    # sensors_data_train[i*ntrain : (i+1)*ntrain] = Vxtrain[traj_idx_train, time_idx, sensors_idx_train[:, None, :]] # → (ntrain,201,5)\n","\n","    train_hist[i*ntrain*ntimes : (i+1)*ntrain*ntimes] = Padding(Vxtrain[traj_idx_train, time_idx, sensors_idx_train[:, None, :]], lag).transpose(1,2) #.to(device) # (N_samples, nsensors, lag)\n","    train_out[i*ntrain*ntimes : (i+1)*ntrain*ntimes] = Padding(torch.cat((Vxtrain_POD, Vytrain_POD, MUtrain[:, :, 0].unsqueeze(2)), 2), 1).squeeze(1) #.to(device) # (N_samples, nvelocity)\n","\n","    sensor_coords_exp[i*ntrain*ntimes : (i+1)*ntrain*ntimes] = torch.from_numpy(np.repeat(XY.numpy()[idx_train][np.arange(ntrain)[:, None, None],\n","                      sensors_idx_train[:, :, None],\n","                      np.arange(coord_dim)[None, None, :]], repeats=ntimes, axis=0)).to(torch.float) #.to(device)\n","# field_coords_exp = torch.from_numpy(np.repeat(XY[idx_train], repeats=ntimes*n_sensors_choices_per_trajectory, axis=0)).to(torch.float) #.to(device)\n","\n","# # Load valid dataset\n","# valid_hist = torch.load('data/valid_hist.pt').float().to(device)\n","# sensor_coords_exp_valid = torch.load('data/sensor_coords_exp_valid.pt').float().to(device)\n","# valid_out = torch.load('data/valid_out.pt').float().to(device)\n","\n","# Generate valid dataset\n","valid_hist = torch.zeros((n_sensors_choices_per_trajectory * nvalid * ntimes, nsensors, lag)).to(device)\n","valid_out = torch.zeros((n_sensors_choices_per_trajectory * nvalid * ntimes, kvelocity + 1)).to(device)\n","sensor_coords_exp_valid = torch.zeros((n_sensors_choices_per_trajectory * nvalid * ntimes, nsensors, coord_dim)).to(device)\n","for i in range(n_sensors_choices_per_trajectory):\n","    sensors_idx_valid = np.stack([\n","        np.random.choice(nvelocity, nsensors, replace=False)\n","        for _ in range(nvalid)\n","    ], axis=0)\n","\n","    traj_idx_valid    = np.arange(nvalid)[:, None, None]   # (nvalid,1,1)\n","    time_idx          = np.arange(ntimes)[None, :, None]   # (1,201,1)\n","\n","    valid_hist[i*nvalid*ntimes : (i+1)*nvalid*ntimes] = Padding(Vxvalid[traj_idx_valid, time_idx, sensors_idx_valid[:, None, :]], lag).transpose(1,2) #.to(device) # (N_samples, nsensors, lag)\n","    valid_out[i*nvalid*ntimes : (i+1)*nvalid*ntimes] = Padding(torch.cat((Vxvalid_POD, Vyvalid_POD, MUvalid[:, :, 0].unsqueeze(2)), 2), 1).squeeze(1) #.to(device) # (N_samples, nvelocity)\n","\n","    sensor_coords_exp_valid[i*nvalid*ntimes : (i+1)*nvalid*ntimes] = torch.from_numpy(np.repeat(XY.numpy()[idx_valid][np.arange(nvalid)[:, None, None],\n","                      sensors_idx_valid[:, :, None],\n","                      np.arange(coord_dim)[None, None, :]], repeats=ntimes, axis=0)).to(torch.float) #.to(device)\n"]},{"cell_type":"code","source":["# Instantiate datasets and loaders\n","train_dataset = SensorFieldDataset(train_hist, sensor_coords_exp, train_out)\n","train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=True)\n","valid_dataset = SensorFieldDataset(valid_hist, sensor_coords_exp_valid, valid_out)\n","valid_loader = DataLoader(valid_dataset, batch_size=2048, shuffle=True)"],"metadata":{"id":"88zKr4OXc8Z3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p_1mHaG0q19P"},"outputs":[],"source":["# # Dataset su disco\n","\n","# # # Salva i tensori sul disco in formato .pt\n","# # torch.save(train_hist, 'train_hist.pt')\n","# # torch.save(sensor_coords_exp, 'sensor_coords_exp.pt')\n","# # torch.save(train_out, 'train_out.pt')\n","\n","# class TorchSensorFieldDataset(Dataset):\n","#     def __init__(self, hist_path, coords_path, out_path):\n","#         # Carica i tensori in CPU (non occupano GPU fino all'utilizzo)\n","#         self.hist = torch.load(hist_path, map_location='cpu')\n","#         self.coords = torch.load(coords_path, map_location='cpu')\n","#         self.out = torch.load(out_path, map_location='cpu')\n","#         assert len(self.hist) == len(self.coords) == len(self.out)\n","\n","#     def __len__(self):\n","#         return self.hist.size(0)\n","\n","#     def __getitem__(self, idx):\n","#         # Slicing diretto su PyTorch Tensor non genera warning\n","#         hist = self.hist[idx]\n","#         coords = self.coords[idx]\n","#         out = self.out[idx]\n","#         return hist, coords, out\n","\n","# # Crea il dataset \"Torch\"\n","# train_dataset = TorchSensorFieldDataset(\n","#     hist_path='data/train_hist.pt',\n","#     coords_path='data/sensor_coords_exp.pt',\n","#     out_path='data/train_out.pt'\n","# )\n","\n","# # DataLoader (usa num_workers=2 o 0 se necessario per il tuo sistema)\n","# train_loader = DataLoader(\n","#     train_dataset,\n","#     batch_size=2048,\n","#     shuffle=True,\n","#     num_workers=2,    # regola in base alle risorse disponibili\n","#     pin_memory=True   # ottimizza trasferimento a GPU\n","# )\n","\n","# valid_dataset = TorchSensorFieldDataset(\n","#     hist_path='data/valid_hist.pt',\n","#     coords_path='data/sensor_coords_exp_valid.pt',\n","#     out_path='data/valid_out.pt'\n","# )\n","# valid_loader = DataLoader(\n","#     valid_dataset,\n","#     batch_size=2048,\n","#     shuffle=True,\n","#     num_workers=2,    # regola in base alle risorse disponibili\n","#     pin_memory=True   # ottimizza trasferimento a GPU\n","# )\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XkAAzEkqowmR"},"outputs":[],"source":["# Instantiate model (using the modified SHRED)\n","# latent_dim chosen as you prefer\n","latent_dim = 128\n","output_size = kvelocity + 1\n","model = SHREDagnosticAttention(coord_dim=coord_dim,\n","              latent_dim=latent_dim,\n","              output_size=output_size,\n","              hidden_size=64,\n","              lstm_layers=2,\n","              decoder_sizes=[350, 400, output_size],\n","              dropout=0.1)\n","\n","import time\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","def fit_agnostic(model,\n","                 train_loader,\n","                 valid_loader,\n","                 epochs=100,\n","                 lr=1e-3,\n","                 loss_fun=torch.nn.MSELoss(),\n","                 patience=50,\n","                 factor=0.8,\n","                 plateau_patience=20):\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    scheduler = ReduceLROnPlateau(\n","        optimizer,\n","        mode='min',\n","        factor=factor,\n","        patience=plateau_patience,\n","        # verbose=True\n","    )\n","    history = {'train_loss': [], 'valid_loss': [], 'epoch_time': []}\n","\n","    best_model_wts = deepcopy(model.state_dict())\n","    best_loss = float('inf')\n","    epochs_no_improve = 0\n","\n","    for epoch in range(1, epochs + 1):\n","        epoch_start = time.time()\n","        running_train_loss = 0.0\n","        running_valid_loss = 0.0\n","\n","        # tot_batches = train + valid\n","        tot_batches = len(train_loader) + len(valid_loader)\n","        pbar = tqdm(total=tot_batches,\n","                    desc=f\"Epoch {epoch}/{epochs}\",\n","                    unit=\"batch\",\n","                    leave=False)\n","\n","        # --- TRAIN ---\n","        model.train()\n","        for hist, coords, tgt in train_loader:\n","            optimizer.zero_grad()\n","            pred, _ = model(hist, coords)\n","            loss = loss_fun(pred, tgt)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_train_loss += loss.item() * hist.size(0)\n","            pbar.set_postfix(stage='train', loss=f\"{loss.item():.4f}\")\n","            pbar.update(1)\n","\n","        avg_train_loss = running_train_loss / len(train_loader.dataset)\n","\n","        # --- VALID ---\n","        model.eval()\n","        with torch.no_grad():\n","            for hist, coords, tgt in valid_loader:\n","                pred, _ = model(hist, coords)\n","                loss_val = loss_fun(pred, tgt)\n","\n","                running_valid_loss += loss_val.item() * hist.size(0)\n","                pbar.set_postfix(stage='valid', loss=f\"{loss_val.item():.4f}\")\n","                pbar.update(1)\n","\n","        avg_valid_loss = running_valid_loss / len(valid_loader.dataset)\n","\n","        pbar.close()\n","        epoch_time = time.time() - epoch_start\n","\n","        scheduler.step(avg_valid_loss)\n","\n","        # Early stopping\n","        if avg_valid_loss < best_loss:\n","            best_loss = avg_valid_loss\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","            epochs_no_improve = 0\n","        else:\n","            epochs_no_improve += 1\n","\n","        # Logging\n","        history['train_loss'].append(avg_train_loss)\n","        history['valid_loss'].append(avg_valid_loss)\n","        history['epoch_time'].append(epoch_time)\n","        print(\n","            f\"Epoch {epoch}/{epochs} | \"\n","            f\"Train: {avg_train_loss:.6f} | \"\n","            f\"Valid: {avg_valid_loss:.6f} | \"\n","            f\"lr: {scheduler.get_last_lr()[0]:.6f} | \"\n","            f\"Time: {epoch_time:.1f}s | \"\n","            f\"NoImprove: {epochs_no_improve}/{patience}\"\n","        )\n","\n","        if epochs_no_improve >= patience:\n","            print(f\"\\nEarly stopping: valid loss non migliora da {patience} epoche.\")\n","            break\n","\n","    model.load_state_dict(best_model_wts)\n","    return history\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CWU13TCRowmR"},"outputs":[],"source":["if torch.cuda.device_count() > 1:\n","    print(f\"Using {torch.cuda.device_count()} GPUs\")\n","    model = torch.nn.DataParallel(model)\n","\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZnOHtnKRowmR"},"outputs":[],"source":["# Run training\n","history = fit_agnostic(model, train_loader, valid_loader, epochs=500, lr=1e-3, patience=100, plateau_patience=20, factor=0.8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qmSwUO4towmR"},"outputs":[],"source":["# # Assumendo che `model` sia un'istanza di SHREDagnostic\n","torch.save(model.state_dict(), \"shred_agnostic___.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PGHpr4_U28fy"},"outputs":[],"source":["# model.load_state_dict(torch.load( \"shred_agnostic_400ep.pth\", weights_only=True, map_location=torch.device('cpu')))\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pt8gkatVowmR"},"outputs":[],"source":["àtorch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dHbkV3Tn92zb"},"outputs":[],"source":["Vtest = torch.sqrt(Vxtest**2 + Vytest**2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lVfR_yWnmPPa"},"outputs":[],"source":["# COLORMAP\n","\n","# import seaborn as sns\n","# from matplotlib import colors\n","# ice = sns.color_palette(\"icefire\", as_cmap=True).colors\n","# col = [ice[i] for i in np.concatenate((np.arange(128,0,-10), np.arange(254,128,-9)))]\n","# col.insert(0, \"black\")\n","# cmap = colors.LinearSegmentedColormap.from_list(\"\", col)\n","\n","cmap = \"jet\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XJNn0W2hvGpj"},"outputs":[],"source":["from matplotlib.colors import Normalize\n","from matplotlib import cm\n","import imageio\n","from mpl_toolkits.axes_grid1 import make_axes_locatable\n","from matplotlib.transforms import Bbox\n","\n","def trajectories_with_sensors(yts, plot, sensors_coordinates_list,\n","                              cmap=None, titles=None, fontsize=None, figsize=None, vertical=False, axis=False, save=False, name='gif', plot_sensors = True, display_ = True):\n","    arrays = []\n","    # num_sensors = len(sensors_coordinates)\n","\n","    vmin = min(np.abs(yts[i]).min() for i in range(len(yts)))\n","    vmax = max(np.abs(yts[i]).max() for i in range(len(yts)))\n","    norm = Normalize(vmin = vmin, vmax = vmax)\n","\n","    if save:\n","        writer = imageio.get_writer(name.replace(\".gif\", \"\") + \".gif\", mode='I', duration=0.1)\n","\n","    for i in range(yts[0].shape[0]):\n","        fig, axs = plt.subplots(len(yts) if vertical else 1, 1 if vertical else len(yts), figsize=figsize)\n","        axs = np.atleast_1d(axs)\n","\n","        for j, ax in enumerate(axs):\n","            plt.sca(ax)\n","            plot(yts[j][i], norm=norm, cmap = cmap)\n","            # if (j == len(yts) - 2) & plot_sensors:\n","            #     for k in range(num_sensors):\n","            #         ax.plot(sensors_coordinates[k, 0], sensors_coordinates[k, 1], 'o', mfc='magenta', mec='black', ms=8, mew=1.5)\n","            sensors_coordinates = sensors_coordinates_list[j]\n","            if not (sensors_coordinates == []):\n","                num_sensors = len(sensors_coordinates)\n","                if titles[j] == \"SHRED prediction (sensor walk)\":\n","                    for i in range(num_sensors):\n","                        traj = np.array([step[i] for step in sensors_history])\n","                        plt.gca().plot(traj[:, 0], traj[:, 1], color='magenta', label='_nolegend_', linewidth = 1)\n","                        plt.gca().scatter(traj[0, 0], traj[0, 1], color='magenta', edgecolors='k', marker='o', s = 10, label='_nolegend_')\n","                        plt.gca().scatter(traj[-1, 0], traj[-1, 1], color='magenta', edgecolors='k', marker='X', s=100, label='_nolegend_')\n","                        # plt.gca().plot(traj[0, 0], traj[0, 1], mfc='magenta', mec='black', marker='o', ms=8, mew=1.5, alpha = 0.5, label='_nolegend_')\n","                        # plt.gca().scatter(traj[-1, 0], traj[-1, 1], mfc='magenta', mec='black', marker='X', ms=8, mew=1.5, alpha = 1, label='_nolegend_')\n","                    plt.gca().scatter([], [], color='magenta', edgecolors='k', marker='o', label='Start')\n","                    plt.gca().scatter([], [], color='magenta', edgecolors='k', marker='X', s=100, label='End')\n","                    plt.gca().legend(loc = \"upper right\")\n","                else:\n","                    for k in range(num_sensors):\n","                        # ax.plot(sensors_coordinates[k, 0], sensors_coordinates[k, 1], 'o', mfc='magenta', mec='black', marker='X', ms=8, mew=1.5)\n","                        ax.scatter(sensors_coordinates[k, 0], sensors_coordinates[k, 1], color='magenta', edgecolors='k', marker='X', s=100, label='_nolegend_')\n","            if titles:\n","                ax.set_title(titles[j], fontsize=fontsize)\n","            if not axis:\n","                ax.axis('off')\n","\n","        plt.colorbar(\n","              cm.ScalarMappable(cmap=cmap, norm=norm),\n","              # ax=axs[0],\n","              cax = fig.add_axes([-0.01, 0.35, 0.01, 0.3]),\n","              location=\"left\",\n","              orientation=\"vertical\",\n","              pad=0.02,           # più piccolo = meno distanza\n","              fraction=0.04,      # più piccolo = colorbar più sottile\n","              aspect=40           # opzionale, controlla il rapporto larghezza/altezza\n","            )\n","\n","        fig.tight_layout()\n","        if display_:\n","            display(fig)\n","        # costrusci fig e ottieni `frame = np.array(fig.canvas.renderer.buffer_rgba())`\n","        if save:\n","            writer.append_data((np.array(fig.canvas.renderer.buffer_rgba())))\n","        plt.close(fig)\n","        clc(wait=True)\n","\n","    if save:\n","        writer.close()\n","    # if save:\n","    #     imageio.mimsave(name.replace(\".gif\", \"\") + \".gif\", arrays)"]},{"cell_type":"code","source":["whichtimes = np.arange(0, 200, 5)\n","# whichtrajectory = np.random.choice(ntest)\n","whichtrajectory = 19\n","mult = 4\n","\n","nsensors_test = int(nsensors * mult)\n","\n","sensors_idx_test = np.random.choice(nvelocity, nsensors_test, replace=False)\n","# sensors_idx_test = sensors_idx_test[None, :]      # (1, nsensors_test)\n","\n","# sensors_data_test = Vxtest[traj_idx_test, time_idx, sensors_idx_test].unsqueeze(0) (1, ntimes, nsensors_test)\n","sensors_data_test = Vxtest[whichtrajectory, :, sensors_idx_test].unsqueeze(0) # (1, ntimes, nsensors_test)\n","test_hist = Padding(sensors_data_test, lag).transpose(1,2) # (ntimes, lag, nsensors_test)\n","\n","sensors_coords_test = XY[idx_test][whichtrajectory][sensors_idx_test].unsqueeze(0) # (1, nsensors_test, 2)\n","\n","model.eval();\n","with torch.no_grad():\n","    Vtest_POD = model(test_hist.to(device).contiguous(), sensors_coords_test.repeat(ntimes, 1, 1).to(device))[0][:, :-1]\n","Vtest_hat = torch.sqrt((torch.from_numpy(scalerVx.inverse_transform(Vtest_POD.detach().cpu().numpy()[:,:kvelocity//2])).float() @ Wx).view(1, ntimes, nvelocity)**2 \\\n","                      + \\\n","                      (torch.from_numpy(scalerVy.inverse_transform(Vtest_POD.detach().cpu().numpy()[:,kvelocity//2:])).float() @ Wy).view(1, ntimes, nvelocity)**2)\n","\n","# plotlist = [Vtest[whichtrajectory, whichtimes], Vtest_hat.numpy()[0, whichtimes], Vtest[whichtrajectory, whichtimes] - Vtest_hat.numpy()[0, whichtimes]]\n","plotlist = [\n","        Vtest[whichtrajectory, whichtimes],\n","        Vtest_hat.numpy()[0, whichtimes],\n","        # Vtest_hat_qrpiv.numpy()[0, whichtimes],\n","        Vtest[whichtrajectory, whichtimes] - Vtest_hat.numpy()[0, whichtimes],\n","        ]\n","titles = (\n","          \"Velocity trajectory\",\n","          \"SHRED prediction\",\n","          # \"SHRED prediction (qr-pivoted sensors)\",\n","          \"Prediction error\",\n","          )\n","sensors_coordinates_list  = [\n","                            [],\n","                            sensors_coords_test[0],\n","                            # sensors_coords_test_qrpiv[0],\n","                            [],\n","                            ]\n","\n","params_geo = MUtest[whichtrajectory, 0, 2:]\n","# redefine plot_v on new triang\n","_, triang = update_coords_and_triang(params_geo)\n","def plot_v(v, triang = triang, norm = None, cmap = cmap):\n","    if not norm == None:\n","        plt.tricontourf(triang, v, cmap = cmap, norm = norm, levels = 200)\n","    else:\n","        plt.tricontourf(triang, v, cmap = cmap, levels = 200)\n","    plt.gca().set_aspect(\"equal\")\n","    add_zoom(zoom = 1.1)\n","\n","trajectories_with_sensors(plotlist, plot_v, sensors_coordinates_list,\n","                      titles = titles,\n","                      figsize = (10, 5), vertical = False,\n","                      # save = True, name = f\"gifs/traj{whichtrajectory}_sens{nsensors_test}\",\n","                      cmap = cmap,\n","                      # plot_sensors = False,\n","                      )"],"metadata":{"id":"zVy3EKrG47bX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OtZ--nO0tmam"},"outputs":[],"source":["import gc\n","whichtimes = np.arange(0, 200, 5)\n","\n","# for whichtrajectory in range(ntest):\n","if False:\n","    for mult in [10]:\n","        for whichtrajectory in range(ntest):\n","            # mult = 10\n","            print(f\"traj {whichtrajectory}, mult {mult}\")\n","            nsensors_test = int(nsensors * mult)\n","\n","            sensors_idx_test = np.random.choice(nvelocity, nsensors_test, replace=False)\n","            # sensors_idx_test = sensors_idx_test[None, :]      # (1, nsensors_test)\n","\n","            # sensors_data_test = Vxtest[traj_idx_test, time_idx, sensors_idx_test].unsqueeze(0) (1, ntimes, nsensors_test)\n","            sensors_data_test = Vxtest[whichtrajectory, :, sensors_idx_test].unsqueeze(0) # (1, ntimes, nsensors_test)\n","            test_hist = Padding(sensors_data_test, lag).transpose(1,2) # (ntimes, lag, nsensors_test)\n","\n","            sensors_coords_test = XY[idx_test][whichtrajectory][sensors_idx_test].unsqueeze(0) # (1, nsensors_test, 2)\n","\n","            model.eval();\n","            with torch.no_grad():\n","                Vtest_POD = model(test_hist.to(device).contiguous(), sensors_coords_test.repeat(ntimes, 1, 1).to(device))[:, :-1]\n","            Vtest_hat = torch.sqrt((torch.from_numpy(scalerVx.inverse_transform(Vtest_POD.detach().cpu().numpy()[:,:kvelocity//2])).float() @ Wx).view(1, ntimes, nvelocity)**2 \\\n","                                  + \\\n","                                  (torch.from_numpy(scalerVy.inverse_transform(Vtest_POD.detach().cpu().numpy()[:,kvelocity//2:])).float() @ Wy).view(1, ntimes, nvelocity)**2)\n","\n","            # plotlist = [Vtest[whichtrajectory, whichtimes], Vtest_hat.numpy()[0, whichtimes], Vtest[whichtrajectory, whichtimes] - Vtest_hat.numpy()[0, whichtimes]]\n","            plotlist = [\n","                    Vtest[whichtrajectory, whichtimes],\n","                    Vtest_hat.numpy()[0, whichtimes],\n","                    # Vtest_hat_qrpiv.numpy()[0, whichtimes],\n","                    Vtest[whichtrajectory, whichtimes] - Vtest_hat.numpy()[0, whichtimes],\n","                    ]\n","            titles = (\n","                      \"Velocity trajectory\",\n","                      \"SHRED prediction\",\n","                      # \"SHRED prediction (qr-pivoted sensors)\",\n","                      \"Prediction error\",\n","                      )\n","            sensors_coordinates_list  = [\n","                                        [],\n","                                        sensors_coords_test[0],\n","                                        # sensors_coords_test_qrpiv[0],\n","                                        [],\n","                                        ]\n","\n","            params_geo = MUtest[whichtrajectory, 0, 2:]\n","            # redefine plot_v on new triang\n","            _, triang = update_coords_and_triang(params_geo)\n","            def plot_v(v, triang = triang, norm = None, cmap = cmap):\n","                if not norm == None:\n","                    plt.tricontourf(triang, v, cmap = cmap, norm = norm, levels = 200)\n","                else:\n","                    plt.tricontourf(triang, v, cmap = cmap, levels = 200)\n","                plt.gca().set_aspect(\"equal\")\n","                add_zoom(zoom = 1.1)\n","\n","            trajectories_with_sensors(plotlist, plot_v, sensors_coordinates_list,\n","                                  titles = titles,\n","                                  figsize = (10, 5), vertical = False, save = True, name = f\"gifs/traj{whichtrajectory}_sens{nsensors_test}\",\n","                                  display_ = False,\n","                                  cmap = cmap,\n","                                  # plot_sensors = False,\n","                                  )\n","\n","            plt.close('all')\n","            gc.collect()\n","\n","            # del Vtest\n","            del sensors_idx_test\n","            del sensors_data_test\n","            del test_hist\n","            del sensors_coords_test\n","            del Vtest_POD\n","            del Vtest_hat\n","            del plotlist"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n6KvkHKZoOe3"},"outputs":[],"source":["del Vtest\n","del sensors_idx_test\n","del sensors_data_test\n","del test_hist\n","del sensors_coords_test\n","del Vtest_POD\n","del Vtest_hat\n","del plotlist\n"]},{"cell_type":"markdown","metadata":{"id":"FVBP8V_c4kBQ"},"source":["### Sensor walk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CCWUQsu5Dw_G"},"outputs":[],"source":["model.load_state_dict(torch.load( \"shred_agnostic_400ep.pth\", weights_only=True, map_location=torch.device('cpu')))\n","model.eval();"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9kc3hCm94jX4"},"outputs":[],"source":["# Le posizioni dei sensori sono variabili trainabili\n","d = coord_dim\n","sensors_coords = torch.rand(nsensors, d, device=device, requires_grad=True)\n","sensors_coords.data.mul_(torch.tensor([L, H], device=device, dtype=torch.float32))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q_P3yH5T5PuY"},"outputs":[],"source":["# Definizione della funzione di Fourier Positional Encoding\n","def fourier_encode(x, B):\n","    \"\"\"\n","    Applica il positional encoding Fourier alle coordinate.\n","\n","    Parametri:\n","      - x: tensor di shape (n, d) (ad esempio, coordinate spaziali)\n","      - B: tensor di shape (d, D) contenente le frequenze.\n","\n","    Restituisce:\n","      - encoding: tensor di shape (n, 2*D) ottenuto concatenando sin(xB) e cos(xB).\n","    \"\"\"\n","    # Proiezione: x @ B produce un tensore di shape (n, D)\n","    x_proj = 2 * torch.pi * x @ B\n","    return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n","\n","# Setup dei parametri e degli input\n","D = 16  # dimensione scelta per la proiezione (puoi variare questo parametro)\n","B = torch.randn(d, D).to(device)\n"]},{"cell_type":"code","source":["class SensorDataInterpolator(torch.nn.Module):\n","    def __init__(self, B, device = device):\n","        \"\"\"\n","        XY: torch.Tensor di shape (ntraj, nvelocity, 2) -> coordinate dei nodi per traiettoria\n","        Vxtrain: torch.Tensor di shape (ntraj, ntimes, nvelocity) -> valori sui nodi (statici nel tempo)\n","        B: torch.Tensor di shape (2, D) -> matrice di frequenze per il Fourier encoding\n","        \"\"\"\n","        super().__init__()\n","        self.B = B\n","        self.device = device\n","\n","    def forward(self, sensors_coords, Vxtrain, node_encodings):\n","        \"\"\"\n","        sensors_coords: torch.Tensor di shape (nsensors, 2  D) (trainable)\n","\n","        Restituisce:\n","           sensor_data: tensor di shape (ntraj, ntimes, nsensors) ottenuto come interpolazione differenziabile\n","           dei valori Vxtrain nei nuovi punti dati dai sensors_coords_encoded.\n","        \"\"\"\n","\n","        ntraj, nvelocity, ntimes = Vxtrain.shape\n","        # print(Vxtrain.shape)\n","\n","        nsensors = sensors_coords.shape[0]\n","        # Calcola l'encoding dei sensori\n","        sensor_encodings = fourier_encode(sensors_coords, self.B).to(self.device)  # shape: (nsensors, 2*D)\n","        # print(sensor_encodings.shape)\n","        # node_encodings: (ntraj, nvelocity, 2*D); vogliamo il prodotto scalare tra\n","        # ogni sensore ed ogni nodo per ogni traiettoria.\n","        # Risulta una similarità di shape: (ntraj, nsensors, nvelocity)\n","\n","        # nsensors = sensor_encodings.shape[0]\n","\n","        sensor_encodings_expanded = sensor_encodings.unsqueeze(0)  # (1, nsensors, 2*D)\n","        # print(sensor_encodings_expanded.shape)\n","        similarity = torch.matmul(sensor_encodings_expanded, node_encodings.transpose(1,2)).to(self.device)\n","        # print(similarity.shape)\n","\n","        # Softmax lungo l'asse dei nodi per ottenere i pesi\n","        weights = F.softmax(similarity, dim=2).to(self.device)  # shape: (ntraj, nsensors, nvelocity)\n","        # print(weights.shape)\n","        # Per eseguire la somma pesata sui valori:\n","        # Vxtrain: (ntraj, ntimes, nvelocity)\n","        # Per la moltiplicazione batch, bisogna trasporre i pesi: (ntraj, nvelocity, nsensors)\n","        weights_t = weights.transpose(1,2)  # (ntraj, nvelocity, nsensors)\n","        # print(weights_t.shape)\n","        # print(Vxtrain.shape)\n","\n","        sensor_vals = torch.matmul(Vxtrain, weights_t).to(self.device)\n","\n","        return sensor_vals"],"metadata":{"id":"9ZuKDuPMFUZ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gBZAmrn35cm_"},"outputs":[],"source":["lag = 50\n","# optim_cls=torch.optim.Adam\n","lr_shred=1e-3\n","lr_sensors=0.1\n","batch_size = ntimes\n","epochs = 100\n","print_every_epochs = 5\n","update_sensors_every_steps = 20\n","scatter_sensors_every_steps = epochs\n","\n","loss_fun = mse\n","loss_output = mre\n","formatter = num2p\n","\n","train_error_list = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IimE3I4f5sT3"},"outputs":[],"source":["whichtrajectory = 11 # np.random.choice(ntest)\n","\n","# Preinizializza l'ottimizzatore con i parametri del modello e anche sensors_coords\n","# Definisci due ottimizzatori:\n","optimizer_model = torch.optim.Adam(model.parameters(), lr=lr_shred)           # per il modello SHRED\n","optimizer_sensors = torch.optim.Adam([sensors_coords], lr=lr_sensors)         # per le coordinate dei sensori\n","\n","node_encodings = fourier_encode(XY[whichtrajectory].unsqueeze(0).view(-1, XY.shape[-1]).to(device), B.to(device)).view(1, nvelocity, -1)\n","data_out = Padding(torch.cat((Vxtest_POD[whichtrajectory].unsqueeze(0),\n","                                    Vytest_POD[whichtrajectory].unsqueeze(0),\n","                                    MUtest[whichtrajectory,:,0].unsqueeze(0).unsqueeze(2)), 2), 1).squeeze(1).to(device)\n","sensor_interpolator = SensorDataInterpolator(B.to(device)).to(device)  # o device appropriato\n","sensors_data = sensor_interpolator(sensors_coords, Vxtest[whichtrajectory].unsqueeze(0).to(device), node_encodings.to(device))  # shape (ntraj, ntimes, nsensors)\n","train_dataset = TimeSeriesDataset(Padding(sensors_data, lag).to(device), data_out)\n","\n","out_data_loader = DataLoader(data_out, shuffle=False, batch_size=batch_size)\n","sensors_history = [sensors_coords.detach().cpu().numpy()]"]},{"cell_type":"code","source":["# Assumiamo:\n","# - model: SHREDagnostic pretrained e messo in eval\n","# - sensor_interpolator: operatore che genera sensor_data\n","# - Padding, TimeSeriesDataset definiti\n","# - Vxtest, Vytest, MUtest, XY, Vxtest_POD, Vytest_POD, MUtest disponibili\n","# - mse, mre, num2p definiti\n","# - device, L, H, coord_dim, nsensors, lag, batch_size\n","\n","# 1. Funzione per valutare una configurazione di sensori senza aggiornare i pesi del modello\n","\n","def evaluate_coords(sensors_coords, whichtrajectory, batch_size):\n","    \"\"\"\n","    Restituisce la loss di validazione (mse) per una data configurazione sensors_coords.\n","    sensors_coords: Tensor(nsensors, 2)\n","    \"\"\"\n","    model.eval()\n","    with torch.no_grad():\n","        # genera dati sensori e dataset\n","        node_enc = fourier_encode(\n","            XY[whichtrajectory].unsqueeze(0).view(-1, XY.shape[-1]).to(device), B\n","        ).view(1, nvelocity, -1)\n","        sensor_data = sensor_interpolator(\n","            sensors_coords.to(device),\n","            Vxtest[whichtrajectory].unsqueeze(0).to(device),\n","            node_enc\n","        )\n","        in_data = Padding(sensor_data, lag).transpose(1,2).contiguous().to(device)\n","        coords_exp = sensors_coords.unsqueeze(0).expand(batch_size, -1, -1).contiguous().to(device)\n","        outputs = model(in_data, coords_exp)\n","        # assumiamo out_batch disponibile o usiamo data_out directly\n","        out_batch = data_out.to(device)\n","        loss_val = mse(outputs, out_batch)\n","    return loss_val.item()\n","\n","# 2. Multi-start + selezione\n","\n","def multi_start_select(K=20, M=5, whichtrajectory=0):\n","    \"\"\"\n","    Campiona K configurazioni casuali, valuta e ritorna le top-M\n","    \"\"\"\n","    all_coords = []\n","    losses = []\n","    for i in range(K):\n","        # campiona uniformemente su [0,L]x[0,H]\n","        coords = torch.rand(nsensors, coord_dim, device=device)\n","        coords.data.mul_(torch.tensor([L, H], device=device, dtype=torch.float32))\n","        loss_i = evaluate_coords(coords, whichtrajectory, batch_size)\n","        all_coords.append(coords)\n","        losses.append(loss_i)\n","        print(f\"trial n° {i+1}; loss: {loss_i:2f}\")\n","    losses = torch.tensor(losses)\n","    topk = torch.topk(-losses, M)  # massimi negativi = minimi\n","    best_coords = [all_coords[i] for i in topk.indices]\n","    return best_coords, losses[topk.indices]\n","\n","# 3. Rifinitura locale con gradient descent\n","\n","def refine_coords(init_coords, lr=1e-1, steps=100, whichtrajectory=0):\n","    \"\"\"\n","    Data una configurazione iniziale, aggiorna sensors_coords con Adam per 'steps' iterazioni,\n","    mantenendo il modello fisso (o opzionalmente fine-tuning congiunto)\n","    \"\"\"\n","    coords = init_coords.clone().detach().to(device)\n","    coords.requires_grad = True\n","    optimizer = torch.optim.Adam([coords], lr=lr)\n","    for _ in range(steps):\n","        model.eval()\n","        node_enc = fourier_encode(\n","            XY[whichtrajectory].unsqueeze(0).view(-1, XY.shape[-1]).to(device), B\n","        ).view(1, nvelocity, -1)\n","        sensor_data = sensor_interpolator(\n","            coords, Vxtest[whichtrajectory].unsqueeze(0).to(device), node_enc\n","        )\n","        in_batch = Padding(sensor_data, lag).transpose(1,2).contiguous()\n","        coords_exp = coords.expand(batch_size, -1, -1).contiguous()\n","        outputs = model(in_batch, coords_exp)\n","        loss = mse(outputs, data_out.to(device))\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        # riflettere i sensori entro domenio\n","        coords.data = reflect_with_grad_flip(coords.data, L, H)\n","    final_loss = evaluate_coords(coords.detach(), whichtrajectory, batch_size)\n","    return coords.detach(), final_loss\n","\n","# 4. Main routine\n"],"metadata":{"id":"8vY4BaSCCfqf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Parametri multi-start e refine\n","K = 30   # numero di partenza random\n","M = 5    # seleziona top M\n","steps_refine = 50\n","lr_refine = 0.05\n","\n","# 4.1 Multi-start + selezione\n","best_inits, init_losses = multi_start_select(K=K, M=M, whichtrajectory=whichtrajectory)\n","print(\"Initial top losses:\", init_losses)\n","\n","# 4.2 Rifinitura su ognuna\n","refined = []\n","refined_losses = []\n","for init in best_inits:\n","    coords_ref, loss_ref = refine_coords(init, lr=lr_refine, steps=steps_refine, whichtrajectory=whichtrajectory)\n","    refined.append(coords_ref)\n","    refined_losses.append(loss_ref)\n","refined_losses = torch.tensor(refined_losses)\n","best_idx = torch.argmin(refined_losses)\n","\n","best_coords = refined[best_idx]\n","print(f\"Best refined loss: {refined_losses[best_idx]}\")\n","\n","# Ora best_coords è la migliore configurazione trovata\n","sensors_coords = best_coords.clone().detach().requires_grad_(True)\n","# Prosegui eventualmente col training congiunto su modello + sensori..."],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"cirxkdTUChxG","executionInfo":{"status":"error","timestamp":1746063350288,"user_tz":-120,"elapsed":2,"user":{"displayName":"Adriano Racano","userId":"12887391736974890682"}},"outputId":"4d2512f0-34ce-493b-9358-9d093b0a816f"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'whichtrajectory' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-ce9bcea0fc98>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 4.1 Multi-start + selezione\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mbest_inits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_start_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhichtrajectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhichtrajectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initial top losses:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'whichtrajectory' is not defined"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OetTmhdN06g0"},"outputs":[],"source":["# !pip install scikit-optimize\n","# from skopt import gp_minimize\n","# # 1) BO: valutazioni iniziali\n","# def objective(flat_coords):\n","#     # converto in NumPy array e poi reshape\n","#     coords_np = np.array(flat_coords, dtype=np.float32).reshape(nsensors, d)\n","#     coords = torch.from_numpy(coords_np).to(device)\n","\n","#     with torch.no_grad():\n","#         sensor_data = sensor_interpolator(coords, Vxtest[whichtrajectory].unsqueeze(0), node_encodings)\n","#         in_batch = Padding(sensor_data, lag).transpose(1,2).contiguous()\n","#         outputs = model(in_batch.to(device), coords.unsqueeze(0).expand(batch_size, -1, -1).contiguous())\n","#         loss = mse(outputs, data_out)\n","#     return loss.item()\n","\n","# # Limiti per BO: [0,L] e [0,H] per ogni dimensione\n","# bounds = [(0, L), (0, H)] * nsensors\n","\n","# res = gp_minimize(objective, bounds, n_calls=30, random_state=42)\n","\n","# # 2) Warm-start del gradiente\n","# best_coords = torch.tensor(res.x, device=device).view(nsensors, d)\n","# sensors_coords.data.copy_(best_coords)\n","# # 2) Crei un nuovo leaf da cui far partire il gradiente\n","# sensors_coords = best_coords.float().clone().detach().requires_grad_(True)\n","\n","# # 3) Ricostruisci l’ottimizzatore sui nuovi leaf\n","# optimizer_sensors = torch.optim.Adam([sensors_coords], lr=lr_sensors)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FVWJ8KD78V1Y"},"outputs":[],"source":["for epoch in range(epochs):\n","    # print(f\"epoch {epoch}\")\n","    for batch_idx, out_batch in enumerate(out_data_loader):\n","        model.train()\n","        # sensors_coords = torch.rand(nsensors, d, device=device, requires_grad=False)\n","        # sensors_coords.data.mul_(torch.tensor([L, H], device=device, dtype=torch.float32))\n","        sensor_data = sensor_interpolator(\n","            sensors_coords.to(device),\n","            Vxtest[whichtrajectory].unsqueeze(0).to(device),\n","            node_encodings.to(device),\n","        )\n","\n","        in_batch = Padding(sensor_data, lag).transpose(1,2).contiguous().to(device)\n","        sensors_coords_expanded = sensors_coords.unsqueeze(0).expand(batch_size, -1, -1).contiguous()\n","\n","        # Procedi con il resto del forward e backward\n","        optimizer_model.zero_grad()\n","        optimizer_sensors.zero_grad()\n","        outputs = model(in_batch, sensors_coords_expanded)\n","        loss = loss_fun(outputs, out_batch)\n","        loss.backward()\n","        optimizer_model.step()\n","        optimizer_sensors.step()\n","\n","        sensors_coords.data = reflect_with_grad_flip(sensors_coords.data, L, H)\n","\n","    sensors_history.append(sensors_coords.detach().cpu().numpy())\n","    # Logging e validazione\n","    if epoch % print_every_epochs == 0:\n","        model.eval()\n","        with torch.no_grad():\n","            train_error = loss_output(train_dataset.Y, model(train_dataset.X.transpose(1,2).contiguous().to(device), sensors_coords_expanded))\n","            train_error_list.append(train_error)\n","        print(f\"Epoch {epoch}: Training loss = {formatter(train_error_list[-1])}\")\n","\n","    # if epoch % scatter_sensors_every_steps == 0:\n","    #     print(sensors_coords.detach().cpu().numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EaVhKqIGk51Z"},"outputs":[],"source":["# # calcolo l’output del tuo modello e la loss J\n","# sensors_coords = torch.rand(nsensors, d, device=device, requires_grad=True)\n","# sensors_coords.data.mul_(torch.tensor([L, H], device=device, dtype=torch.float32))\n","\n","# timeseries = train_dataset.X.transpose(1,2).contiguous().to(device)\n","# pred = model(timeseries, sensors_coords.unsqueeze(0).expand(len(timeseries), -1, -1).contiguous())\n","# loss = mse(pred, data_out)  # J\n","\n","# # backprop\n","# loss.backward()\n","\n","# # i gradienti sono in sensors.grad\n","# grads = sensors_coords.grad  # shape [N,2], grads[i,0]=∂J/∂x_i, grads[i,1]=∂J/∂y_i\n","# import matplotlib.pyplot as plt\n","\n","# xy = sensors_coords.detach().cpu().numpy()\n","# dx, dy = -grads[:,0].cpu().numpy(), -grads[:,1].cpu().numpy()\n","\n","# plt.figure(figsize=(6,6))\n","# plt.quiver(xy[:,0], xy[:,1], dx, dy, angles='xy', scale_units='xy', scale=1)\n","# plt.xlim(0, L); plt.ylim(0, H)\n","# plt.title(\"Sensitività dei sensori (gradiente di J)\")\n","# plt.xlabel(\"x\"); plt.ylabel(\"y\")\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HWPT3scn0nGD"},"outputs":[],"source":["# XY = np.concatenate((np.expand_dims(X, -1), np.expand_dims(Y, -1)), -1)\n","# XY = XY.reshape(-1, 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bU5HA9_B5bCu"},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m7a8W_K-1Pxa"},"outputs":[],"source":["# pseudo-codice\n","X, Y = np.meshgrid(np.linspace(0,L,100), np.linspace(0,H,100))\n","S = np.zeros_like(X)\n","for i in range(100):\n","  print(f\"i : {i}\")\n","  for j in range(100):\n","    model.train()\n","    sens = sens = torch.tensor(\n","          [[ X[i,j], Y[i,j] ]],\n","          dtype=torch.float32,\n","          requires_grad=True,\n","          device=device\n","    )  # sens è leaf e will accumulate grad\n","    sensor_data = sensor_interpolator(\n","            sens.to(device),\n","            Vxtest[whichtrajectory].unsqueeze(0).to(device),\n","            node_encodings.to(device),\n","        )\n","    timeseries = Padding(sensor_data, lag).transpose(1,2).contiguous().to(device)\n","    J_ij = mse(data_out, model(timeseries, sens.unsqueeze(0).expand(len(timeseries), -1, -1).contiguous()))\n","    J_ij.backward()\n","    S[i,j] = torch.norm(sens.grad).item()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4PN8-KyS_Zb_"},"outputs":[],"source":["S_ = S.copy()\n","# i, j = S.argmax().item() // 100,  S.argmax().item() % 100\n","# S_[i, j] = S_[i, j+1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3pSMut8Q-_rC"},"outputs":[],"source":["fig, ax = plt.subplots()\n","# mesh = ax.pcolormesh(X, Y, S_)\n","mesh = ax.tricontourf(X.reshape(-1), Y.reshape(-1), S_.reshape(-1))\n","ax.set_aspect('equal', adjustable='box')  # qui imposti axis equal\n","add_zoom(1.5)\n","fig.colorbar(mesh, ax=ax, label=\"sensibilità\", aspect = 20, shrink = 0.45, pad = 0.02)\n","plt.fill(naca0012_airfoil_coords[:, 0], naca0012_airfoil_coords[:, 1], facecolor='white',    # interno bianco\n","        #  edgecolor='red',      # bordo rosso\n","         linewidth=1.5)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c7PXoPOl7IJY"},"outputs":[],"source":["min_error_indices = np.where(np.array(train_error_list) <= np.sort(train_error_list)[4])[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bgpz4sov8I3U"},"outputs":[],"source":["plt.figure()\n","colors = [\n","    'red',\n","    'blue',\n","    'green',\n","    'orange',\n","    'purple',\n","    'cyan',\n","    'magenta',\n","    'yellow',\n","    'brown',\n","    'gray'\n","]\n","plt.plot(naca0012_airfoil_coords[:, 0], naca0012_airfoil_coords[:, 1])\n","# markers = [\"x\"] + [\"o\"] * (len(min_error_indices) - 1)\n","for k, i in enumerate(min_error_indices):\n","    plt.scatter(sensors_history[i][0, 0], sensors_history[i][0, 1], marker = \"X\", c = colors[k], label = f\"error = {formatter(train_error_list[i])}\")\n","    plt.scatter(sensors_history[i][-1, 0], sensors_history[i][-1, 1], marker = \"o\", c = colors[k])\n","    # plt.scatter(sensors_history[i][1:, 0], sensors_history[i][1:, 1], marker = \"o\", c = colors[k], label = f\"error = {formatter(train_error_list[i])}\")\n","    plt.plot(sensors_history[i][:, 0], sensors_history[i][:, 1], c = colors[k], linewidth = 1)\n","plt.gca().set_xlim([0, L])\n","plt.gca().set_ylim([0, H])\n","plt.gca().set_aspect(\"equal\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lsQsFEH_OriU"},"outputs":[],"source":["Vtest = torch.sqrt(Vxtest**2 + Vytest**2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0gDUArRWOriU"},"outputs":[],"source":["# import seaborn as sns\n","# from matplotlib import colors\n","# ice = sns.color_palette(\"icefire\", as_cmap=True).colors\n","# col = [ice[i] for i in np.concatenate((np.arange(128,0,-10), np.arange(254,128,-9)))]\n","# col.insert(0, \"black\")\n","# cmap = colors.LinearSegmentedColormap.from_list(\"\", col)\n","\n","cmap = \"jet\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6T6aX59YOriV"},"outputs":[],"source":["from matplotlib.colors import Normalize\n","from matplotlib import cm\n","import imageio\n","from mpl_toolkits.axes_grid1 import make_axes_locatable\n","from matplotlib.transforms import Bbox\n","\n","def trajectories_with_sensors(yts, plot, sensors_coordinates_list,\n","                              cmap=None, titles=None, fontsize=None, figsize=None, vertical=False, axis=False, save=False, name='gif', plot_sensors = True):\n","    arrays = []\n","    # num_sensors = len(sensors_coordinates)\n","\n","    vmin = min(np.abs(yts[i]).min() for i in range(len(yts)))\n","    vmax = max(np.abs(yts[i]).max() for i in range(len(yts)))\n","    norm = Normalize(vmin = vmin, vmax = vmax)\n","\n","    for i in range(yts[0].shape[0]):\n","        fig, axs = plt.subplots(len(yts) if vertical else 1, 1 if vertical else len(yts), figsize=figsize)\n","        axs = np.atleast_1d(axs)\n","\n","        for j, ax in enumerate(axs):\n","            plt.sca(ax)\n","            plot(yts[j][i], norm=norm, cmap = cmap)\n","            # if (j == len(yts) - 2) & plot_sensors:\n","            #     for k in range(num_sensors):\n","            #         ax.plot(sensors_coordinates[k, 0], sensors_coordinates[k, 1], 'o', mfc='magenta', mec='black', ms=8, mew=1.5)\n","            sensors_coordinates = sensors_coordinates_list[j]\n","            if not (sensors_coordinates == []):\n","                num_sensors = len(sensors_coordinates)\n","                if titles[j] == \"SHRED prediction (sensor walk)\":\n","                    for i in range(num_sensors):\n","                        traj = np.array([step[i] for step in sensors_history])\n","                        plt.gca().plot(traj[:, 0], traj[:, 1], color='magenta', label='_nolegend_', linewidth = 1)\n","                        plt.gca().scatter(traj[0, 0], traj[0, 1], color='magenta', edgecolors='k', marker='o', s = 10, label='_nolegend_')\n","                        plt.gca().scatter(traj[-1, 0], traj[-1, 1], color='magenta', edgecolors='k', marker='X', s=100, label='_nolegend_')\n","                        # plt.gca().plot(traj[0, 0], traj[0, 1], mfc='magenta', mec='black', marker='o', ms=8, mew=1.5, alpha = 0.5, label='_nolegend_')\n","                        # plt.gca().scatter(traj[-1, 0], traj[-1, 1], mfc='magenta', mec='black', marker='X', ms=8, mew=1.5, alpha = 1, label='_nolegend_')\n","                    plt.gca().scatter([], [], color='magenta', edgecolors='k', marker='o', label='Start')\n","                    plt.gca().scatter([], [], color='magenta', edgecolors='k', marker='X', s=100, label='End')\n","                    plt.gca().legend(loc = \"upper right\")\n","                else:\n","                    for k in range(num_sensors):\n","                        # ax.plot(sensors_coordinates[k, 0], sensors_coordinates[k, 1], 'o', mfc='magenta', mec='black', marker='X', ms=8, mew=1.5)\n","                        ax.scatter(sensors_coordinates[k, 0], sensors_coordinates[k, 1], color='magenta', edgecolors='k', marker='X', s=100, label='_nolegend_')\n","            if titles:\n","                ax.set_title(titles[j], fontsize=fontsize)\n","            if not axis:\n","                ax.axis('off')\n","\n","        plt.colorbar(\n","              cm.ScalarMappable(cmap=cmap, norm=norm),\n","              # ax=axs[0],\n","              cax = fig.add_axes([-0.01, 0.35, 0.01, 0.3]),\n","              location=\"left\",\n","              orientation=\"vertical\",\n","              pad=0.02,           # più piccolo = meno distanza\n","              fraction=0.04,      # più piccolo = colorbar più sottile\n","              aspect=40           # opzionale, controlla il rapporto larghezza/altezza\n","            )\n","\n","        fig.tight_layout()\n","        display(fig)\n","        if save:\n","            fig.canvas.draw()\n","            arrays.append(np.array(fig.canvas.renderer.buffer_rgba()))\n","        plt.close()\n","        clc(wait=True)\n","\n","    if save:\n","        imageio.mimsave(name.replace(\".gif\", \"\") + \".gif\", arrays)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6gZ6-j86OriU","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"error","timestamp":1746063350327,"user_tz":-120,"elapsed":3,"user":{"displayName":"Adriano Racano","userId":"12887391736974890682"}},"outputId":"1405b08f-a498-4039-956b-48d78413ae90"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'sensors_coords' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-9ad86b153b97>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msensors_coords_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msensors_coords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m sensors_data_test = sensor_interpolator(\n\u001b[1;32m      3\u001b[0m             \u001b[0msensors_coords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mVxtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwhichtrajectory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mnode_encodings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'sensors_coords' is not defined"]}],"source":["sensors_coords_test = sensors_coords.unsqueeze(0).detach()\n","sensors_data_test = sensor_interpolator(\n","            sensors_coords,\n","            Vxtest[whichtrajectory].unsqueeze(0),\n","            node_encodings,\n","        )\n","test_hist = Padding(sensors_data_test, lag).transpose(1,2) # (ntimes, lag, nsensors)\n","\n","Vtest_POD = model(test_hist.to(device).contiguous(), sensors_coords_test.expand(ntimes, -1, -1).contiguous().to(device))[:, :-1]\n","Vtest_hat = torch.sqrt((torch.from_numpy(scalerVx.inverse_transform(Vtest_POD.detach().cpu().numpy()[:,:kvelocity//2])).float() @ Wx).view(1, ntimes, nvelocity)**2 \\\n","                       + \\\n","                       (torch.from_numpy(scalerVy.inverse_transform(Vtest_POD.detach().cpu().numpy()[:,kvelocity//2:])).float() @ Wy).view(1, ntimes, nvelocity)**2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zDpO4i9kEMjT"},"outputs":[],"source":["from sklearn.utils.extmath import randomized_svd\n","import scipy\n","\n","Ux_traj, Sx_traj, Wx_traj = randomized_svd(Vxtest[whichtrajectory].numpy(), n_components = kvelocity//2)\n","# Uy_traj, Sy_traj, Wy_traj = randomized_svd(Vytest[whichtrajectory].numpy(), n_components = kvelocity//2)\n","\n","r = kvelocity//2\n","n_sensors = kvelocity//2\n","if (nsensors <= r):\n","    Q, R, gamma = scipy.linalg.qr(Wx_traj, pivoting = True)\n","else:\n","    Q, R, gamma = scipy.linalg.qr(Wx_traj.transpose() @ Wx, pivoting = True)\n","\n","# gamma = gamma[:nsensors] # undersampled\n","\n","sensors_coords_test_qrpiv = XY[idx_test][whichtrajectory][gamma[:nsensors]].unsqueeze(0) # (1, nsensors_test, 2)\n","sensors_data_test_qrpiv = Vxtest[whichtrajectory, :, gamma[:nsensors]].unsqueeze(0) # (1, ntimes, nsensors_test)\n","test_hist_qrpiv = Padding(sensors_data_test_qrpiv, lag).transpose(1,2) # (ntimes, lag, nsensors)\n","\n","Vtest_POD_qrpiv = model(test_hist_qrpiv.to(device).contiguous(), sensors_coords_test_qrpiv.expand(ntimes, -1, -1).contiguous().to(device))[:, :-1]\n","Vtest_hat_qrpiv = torch.sqrt((torch.from_numpy(scalerVx.inverse_transform(Vtest_POD_qrpiv.detach().cpu().numpy()[:,:kvelocity//2])).float() @ Wx).view(1, ntimes, nvelocity)**2 \\\n","                       + \\\n","                       (torch.from_numpy(scalerVy.inverse_transform(Vtest_POD_qrpiv.detach().cpu().numpy()[:,kvelocity//2:])).float() @ Wy).view(1, ntimes, nvelocity)**2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4mPQYcIOriV"},"outputs":[],"source":["# # FOM vs POD RECONSTRUCTION (PLOTS)\n","# import utils.processdata\n","# importlib.reload(utils.processdata)\n","# from utils.processdata import trajectories_with_sensors\n","\n","whichtimes = np.arange(0, 200, 10)\n","\n","plotlist = [\n","            Vtest[whichtrajectory, whichtimes],\n","            Vtest_hat.numpy()[0, whichtimes],\n","            Vtest_hat_qrpiv.numpy()[0, whichtimes],\n","            # Vtest[whichtrajectory, whichtimes] - Vtest_hat.numpy()[0, whichtimes],\n","            ]\n","titles = (\n","          \"Velocity trajectory\",\n","          \"SHRED prediction (sensor walk)\",\n","          \"SHRED prediction (qr-pivoted sensors)\",\n","          # \"Prediction error\",\n","          )\n","sensors_coordinates_list  = [\n","                             [],\n","                             sensors_coords_test[0],\n","                             sensors_coords_test_qrpiv[0],\n","                             [],\n","                             ]\n","\n","params_geo = MUtest[whichtrajectory, 0, 2:]\n","\n","# redefine plot_v on new triang\n","_, triang = update_coords_and_triang(params_geo)\n","def plot_v(v, triang = triang, norm = None, cmap = cmap):\n","    if not norm == None:\n","        plt.tricontourf(triang, v, cmap = cmap, norm = norm, levels = 200)\n","    else:\n","        plt.tricontourf(triang, v, cmap = cmap, levels = 200)\n","    plt.gca().set_aspect(\"equal\")\n","    add_zoom(zoom = 1.1)\n","\n","trajectories_with_sensors(plotlist, plot_v, sensors_coordinates_list,\n","                          titles = titles,\n","                          figsize = (10, 5), vertical = False, save = False,\n","                          # cmap = cmap,\n","                          cmap = \"RdBu_r\"\n","                          # plot_sensors = False,\n","                          )\n","# trajectories_with_sensors(plotlist, plot_v, idx_sensors, sensors_coords_test[:4][whichtrajectory].detach().cpu().numpy(), titles = (\"Velocity trajectory\", \"SHRED prediction\", \"Prediction error\"), figsize = (10, 5), vertical = False, save = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GDSuZM-8oMQZ"},"outputs":[],"source":["trajectories_with_sensors(plotlist, plot_v, sensors_coordinates_list,\n","                          titles = titles,\n","                          figsize = (10, 5), vertical = False, save = False,\n","                          # cmap = cmap,\n","                          cmap = \"RdBu_r\"\n","                          # plot_sensors = False,\n","                          )\n","# trajectories_with_sensors(plotlist, plot_v, idx_sensors, sensors_coords_test[:4][whichtrajectory].detach().cpu().numpy(), titles = (\"Velocity trajectory\", \"SHRED prediction\", \"Prediction error\"), figsize = (10, 5), vertical = False, save = True)"]},{"cell_type":"markdown","source":["# Old"],"metadata":{"id":"FtXLdjz-Cy4D"}},{"cell_type":"markdown","metadata":{"id":"w89SUJX78BBk"},"source":["### QR_Pivoting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O_ZhLs_YGlV_"},"outputs":[],"source":["from sklearn.utils.extmath import randomized_svd\n","import scipy\n","\n","Ux_traj, Sx_traj, Wx_traj = randomized_svd(Vxtest[whichtrajectory].numpy(), n_components = kvelocity//2)\n","# Uy_traj, Sy_traj, Wy_traj = randomized_svd(Vytest[whichtrajectory].numpy(), n_components = kvelocity//2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"41LDq3aY8BBk"},"outputs":[],"source":["r = kvelocity//2\n","n_sensors = kvelocity//2\n","if (nsensors <= r):\n","    Q, R, gamma = scipy.linalg.qr(Wx_traj, pivoting = True)\n","else:\n","    Q, R, gamma = scipy.linalg.qr(Wx_traj.transpose() @ Wx, pivoting = True)\n","\n","gamma = gamma[:nsensors] # undersampled"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wVIQWpriz6c5"},"outputs":[],"source":["# Sx = np.load(\"data/Sx.npy\")\n","# Ux = np.load(\"data/Ux.npy\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p2pVedO_8BBk"},"outputs":[],"source":["# Ax = np.diag(Sx_traj) @ Ux_traj.transpose()\n","# Wx_t = Wx_traj.transpose()\n","\n","# Ay = np.diag(Sy_traj) @ Uy_traj.transpose()\n","# Wy_t = Wy_traj.transpose()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"amVeppzt8BBk"},"outputs":[],"source":["# # sensors_data_test = Vxtest[whichtrajectory, :, gamma]\n","# Yx = Vxtest[whichtrajectory, :, gamma].numpy().transpose()\n","# Ax_hat = np.linalg.pinv(Wx_t[gamma, :]) @ Yx # Moore-Penrose pseudo-inverse\n","# Vxtest_qrpiv = (Wx_t @ Ax_hat).transpose().reshape(ntimes, nvelocity)\n","\n","# # sensors_data_test = Vxtest[whichtrajectory, :, gamma]\n","# Yy = Vxtest[whichtrajectory, :, gamma].numpy().transpose()\n","# Ay_hat = np.linalg.pinv(Wy_t[gamma, :]) @ Yy # Moore-Penrose pseudo-inverse\n","# Vytest_qrpiv = (Wy_t @ Ay_hat).transpose().reshape(ntimes, nvelocity)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RkfnUq3IApm9"},"outputs":[],"source":["# Vtest_qrpiv = np.sqrt()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"We8_KhqC8BBk"},"outputs":[],"source":["# # FOM vs POD RECONSTRUCTION VS QR-PIVOTING\n","\n","# from utils.processdata import trajectories, trajectories_with_sensors\n","\n","# whichtrajectory = 8\n","# whichtimes = np.arange(0, 200, 10)\n","\n","# plotlist = [Vtest[whichtrajectory, whichtimes], Vtest_reconstructed[whichtrajectory, whichtimes], Vxtest_qrpiv[whichtrajectory, whichtimes]]\n","# params_geo = MUtest[whichtrajectory, 0, 2:]\n","\n","# # redefine plot_v on new triang\n","# coords, triang = update_coords_and_triang(params_geo)\n","# sensors_coordinates = coords[gamma, :2]\n","# def plot_v(v, triang = triang):\n","#     plt.tricontourf(triang, v, cmap = cmap, levels = 200)\n","#     plt.gca().set_aspect(\"equal\")\n","#     add_zoom(zoom = 1.3)\n","\n","# vmin = min(np.abs(plotlist[i]).min() for i in range(len(plotlist)))\n","# vmax = max(np.abs(plotlist[i]).max() for i in range(len(plotlist)))\n","\n","# trajectories_with_sensors(plotlist, plot_v, gamma, sensors_coordinates, titles = (\"Velocity trajectory\", \"POD reconstruction\", \"QR-pivoting reconstruction\"), figsize = (10, 5), vertical = True)"]},{"cell_type":"markdown","metadata":{"id":"2XkhzZ9Owr2i"},"source":["### Training sensori 3 (prova TPU)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KFzz0HBGQ1jd"},"outputs":[],"source":["# !pip install cloud-tpu-client\n","# !pip install torch-xla torch-xla-core\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"luaz118DqmJi"},"outputs":[],"source":["os.chdir(\"../SHRED-ROM\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJpz2R8DlMAI"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B-8murE5R0o0"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","# aggiungi:\n","import torch_xla.core.xla_model as xm\n","import torch_xla.distributed.parallel_loader as pl\n","import torch_xla.distributed.xla_multiprocessing as xmp\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oBmi7mHpwr2j"},"outputs":[],"source":["from copy import deepcopy\n","from IPython.display import clear_output as clc\n","from utils.processdata import mse, mre, num2p\n","\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xU-NXu_Awr2l"},"outputs":[],"source":["import importlib\n","import utils.models\n","import utils.processdata\n","importlib.reload(utils.models)\n","importlib.reload(utils.processdata)\n","import utils.models\n","import utils.processdata\n","from utils.models import SHRED, SHREDagnostic, SHREDTransformer, fit_sensors_coords\n","from utils.processdata import Padding, TimeSeriesDataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ltP4QX2yUCq"},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","\n","# Define custom dataset\n","class SensorFieldDataset(Dataset):\n","    def __init__(self, hist, sensor_coords, targets):\n","        self.hist = hist\n","        self.sensor_coords = sensor_coords\n","        self.targets = targets\n","    def __len__(self):\n","        return self.hist.size(0)\n","    def __getitem__(self, idx):\n","        return (\n","            self.hist[idx],\n","            self.sensor_coords[idx],\n","            self.targets[idx]\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PNjfHludd7YW"},"outputs":[],"source":["# np.savez_compressed(\"data/data.npz\",\n","\n","#     Vxtrain = Vxtrain,\n","#     Vytrain = Vytrain,\n","#     Vxvalid = Vxvalid,\n","#     Vyvalid = Vyvalid,\n","#     Vxtest = Vxtest,\n","#     Vytest = Vytest,\n","#     XY = XY,\n","\n","#     Wx = Wx,\n","#     Wy = Wy,\n","\n","#     Vxtrain_POD = Vxtrain_POD,\n","#     Vxvalid_POD = Vxvalid_POD,\n","#     Vxtest_POD = Vxtest_POD,\n","\n","#     Vytrain_POD = Vytrain_POD,\n","#     Vyvalid_POD = Vyvalid_POD,\n","#     Vytest_POD = Vytest_POD,\n","\n","#     MUtrain = MUtrain,\n","#     MUvalid = MUvalid,\n","#     MUtest = MUtest,\n","\n","#     idx_train = idx_train,\n","#     idx_valid = idx_valid,\n","#     idx_test = idx_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cZu6BCLXq4oK"},"outputs":[],"source":["os.chdir(\"../my_SHRED-ROM\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lZQ6zdntxwnD"},"outputs":[],"source":["os.environ['XLA_METRICS_DEBUG'] = '1'\n","# lancia il training\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IDrGz_f_c_sg"},"outputs":[],"source":["def _mp_fn(rank, flags):\n","    # ogni processo XLA vede un solo core\n","    device = xm.xla_device()\n","\n","    # -------------------- Data Preparation --------------------\n","    # Qui carica o ricevi i tuoi array numpy: Vxtrain, Vytrain, etc.\n","    # Esempio (modifica con i tuoi percorsi / variabili):\n","\n","    # Print device info and world size\n","    device = xm.xla_device()\n","    world_size = xm.xrt_world_size()\n","    xm.master_print(f\"[Core {rank}] Device: {device}, World size: {world_size}\")\n","    xm.master_print(f\"[Core {rank}] Flags: {flags}\")\n","\n","\n","    if (rank == 0):\n","        print(\"Loading data...\")\n","    data = np.load(\"data/data.npz\")\n","\n","    Vxtrain = torch.from_numpy(data[\"Vxtrain\"])\n","    Vytrain = torch.from_numpy(data[\"Vytrain\"])\n","    Vxvalid = torch.from_numpy(data[\"Vxvalid\"])\n","    Vyvalid = torch.from_numpy(data[\"Vyvalid\"])\n","    Vxtest = torch.from_numpy(data[\"Vxtest\"])\n","    Vytest = torch.from_numpy(data[\"Vytest\"])\n","    XY = torch.from_numpy(data[\"XY\"])\n","\n","    Wx = torch.from_numpy(data[\"Wx\"])\n","    Wy = torch.from_numpy(data[\"Wy\"])\n","\n","    Vxtrain_POD = torch.from_numpy(data[\"Vxtrain_POD\"])\n","    Vxvalid_POD = torch.from_numpy(data[\"Vxvalid_POD\"])\n","    Vxtest_POD = torch.from_numpy(data[\"Vxtest_POD\"])\n","\n","    Vytrain_POD = torch.from_numpy(data[\"Vytrain_POD\"])\n","    Vyvalid_POD = torch.from_numpy(data[\"Vyvalid_POD\"])\n","    Vytest_POD = torch.from_numpy(data[\"Vytest_POD\"])\n","\n","    MUtrain = torch.from_numpy(data[\"MUtrain\"])\n","    MUvalid = torch.from_numpy(data[\"MUvalid\"])\n","    MUtest = torch.from_numpy(data[\"MUtest\"])\n","\n","    idx_train = torch.from_numpy(data[\"idx_train\"])\n","    idx_valid = torch.from_numpy(data[\"idx_valid\"])\n","    idx_test = torch.from_numpy(data[\"idx_test\"])\n","\n","    if (rank == 0):\n","        print(\"Data loaded.\")\n","\n","    # Assume mesh_coords is an array of shape (nvelocity, coord_dim) with node coordinates\n","    # and idx_sensors is already defined (indices of selected sensors)\n","    coord_dim = 2  # e.g. 2 for 2D\n","    lag = 50\n","    kvelocity = Vxtrain_POD.size(2) * 2\n","    _, ntimes, nvelocity = Vxtrain.shape\n","\n","    ntrain = len(idx_train) # number of training trajectories\n","    nvalid = len(idx_valid)\n","    ntest = len(idx_test)\n","    nsensors = flags[\"nsensors\"]\n","\n","    n_sensors_choices_per_trajectory = 1\n","    sensors_data_train = torch.zeros((n_sensors_choices_per_trajectory * ntrain, ntimes, nsensors))\n","    train_hist = torch.zeros((n_sensors_choices_per_trajectory * ntrain * ntimes, nsensors, lag))\n","    train_out = torch.zeros((n_sensors_choices_per_trajectory * ntrain * ntimes, kvelocity + 1))\n","    sensor_coords = torch.zeros((n_sensors_choices_per_trajectory * ntrain * ntimes, nsensors, coord_dim))\n","\n","    for i in range(n_sensors_choices_per_trajectory):\n","        sensors_idx_train = np.stack([\n","            np.random.choice(nvelocity, nsensors, replace=False)\n","            for _ in range(n_sensors_choices_per_trajectory * ntrain)\n","        ], axis=0)    # (n_sensors_choices_per_trajectory * ntrain, nsensors)\n","\n","        # sensors_idx_train = indices[idx_train]       # (ntrain,5)\n","        traj_idx_train    = np.arange(ntrain)[:, None, None]   # (ntrain,1,1)\n","        time_idx          = np.arange(ntimes)[None, :, None]   # (1,201,1)\n","        # sensors_idx_train = sensors_idx_train[:, None, :]      # (ntrain,1,5)\n","        sensors_data_train[i*ntrain : (i+1)*ntrain] = Vxtrain[traj_idx_train, time_idx, sensors_idx_train[:, None, :]] # → (ntrain,201,5)\n","\n","        train_hist[i*ntrain*ntimes : (i+1)*ntrain*ntimes] = Padding(sensors_data_train, lag).transpose(1,2) #.to(device) # (N_samples, nsensors, lag)\n","        train_out[i*ntrain*ntimes : (i+1)*ntrain*ntimes] = Padding(torch.cat((Vxtrain_POD, Vytrain_POD, MUtrain[:, :, 0].unsqueeze(2)), 2), 1).squeeze(1) #.to(device) # (N_samples, nvelocity)\n","\n","        sensor_coords[i*ntrain*ntimes : (i+1)*ntrain*ntimes] = torch.from_numpy(np.repeat(XY.numpy()[idx_train][np.arange(ntrain)[:, None, None],\n","                          sensors_idx_train[:, :, None],\n","                          np.arange(coord_dim)[None, None, :]], repeats=ntimes, axis=0)).to(torch.float) #.to(device)\n","    # field_coords_exp = torch.from_numpy(np.repeat(XY[idx_train], repeats=ntimes*n_sensors_choices_per_trajectory, axis=0)).to(torch.float) #.to(device)\n","\n","# 3) Create DataLoaders\n","    train_dataset = SensorFieldDataset(train_hist, sensor_coords, train_out)\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=flags['batch_size'],\n","        shuffle=True,\n","        num_workers=0,\n","        drop_last=True\n","    )\n","    warmup_loader = DataLoader(\n","        train_dataset,\n","        batch_size=flags['warmup_batch_size'],\n","        shuffle=True,\n","        num_workers=0,\n","        drop_last=True\n","    )\n","    xm.master_print(f\"[Core {rank}] train_loader batches={len(train_loader)}, warmup_loader batches={len(warmup_loader)}\")\n","\n","    # 4) Model & optimizer\n","    model = SHREDagnostic(\n","        coord_dim=XY.size(2),\n","        latent_dim=flags['latent_dim'],\n","        output_size=train_out.size(1),\n","        hidden_size=flags['hidden_size'],\n","        lstm_layers=flags['lstm_layers'],\n","        decoder_sizes=flags['decoder_sizes'],\n","        dropout=flags['dropout']\n","    ).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=flags['lr'])\n","    xm.master_print(f\"[Core {rank}] Model on {device}, optimizer lr={flags['lr']}\")\n","\n","    # 5) Warm-up with smaller batch\n","    xm.master_print(f\"[Core {rank}] Warm-up: {flags['warmup_steps']} steps, batch_size={flags['warmup_batch_size']}\")\n","    for step, (h, c, t) in enumerate(warmup_loader, 1):\n","        h, c, t = h.to(device), c.to(device), t.to(device)\n","        xm.master_print(f\"[Core {rank}] Warm-up step {step}: h={h.shape}, c={c.shape}, t={t.shape}\")\n","        _ = model(h, c)\n","        if step >= flags['warmup_steps']:\n","            xm.master_print(f\"[Core {rank}] Warm-up reached {step} steps\")\n","            break\n","    xm.mark_step()\n","    xm.master_print(f\"[Core {rank}] Warm-up complete; graph compiled\")\n","\n","    # 6) Prepare ParallelLoader for training\n","    # Note: in notebooks spawn may run only on core 0.\n","    device_train_loader = pl.ParallelLoader(train_loader, [device]).per_device_loader(device)\n","\n","    # 7) Training loop\n","    for epoch in range(1, flags['epochs'] + 1):\n","        xm.master_print(f\"[Core {rank}] Starting epoch {epoch}/{flags['epochs']}\")\n","        total_loss = 0.0\n","        for batch_idx, (hist, coords, target) in enumerate(device_train_loader, 1):\n","            xm.master_print(f\"[Core {rank}] Epoch {epoch}, batch {batch_idx}\")\n","            optimizer.zero_grad()\n","            pred = model(hist, coords)\n","            loss = F.mse_loss(pred, target)\n","            xm.master_print(f\"[Core {rank}] Loss: {loss.item():.6f}\")\n","            loss.backward()\n","            xm.optimizer_step(optimizer, barrier=True)\n","            xm.mark_step()\n","            total_loss += loss.item() * hist.size(0)\n","        avg_loss = total_loss / len(train_loader.dataset)\n","        xm.master_print(f\"[Core {rank}] Epoch {epoch} done: avg_loss={avg_loss:.6f}\")\n","\n","    # 8) Save checkpoint\n","    if rank == 0:\n","        ckpt_path = os.path.join(flags['output_dir'], 'model_tpu.pth')\n","        torch.save(model.state_dict(), ckpt_path)\n","        xm.master_print(f\"Checkpoint saved: {ckpt_path}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qrGHLqMGgvo0"},"outputs":[],"source":["if __name__ == '__main__':\n","    # Check available XLA devices before spawn\n","    supported = xm.get_xla_supported_devices()\n","    print(\"Supported XLA devices:\", supported)\n","    flags = {\n","        'nsensors': 5,\n","        'lag': 50,\n","        'nsensors': 5,\n","        'batch_size': 1024,\n","        'warmup_batch_size': 128,\n","        'latent_dim': 128,\n","        'hidden_size': 64,\n","        'lstm_layers': 2,\n","        'decoder_sizes': [350, 400],\n","        'dropout': 0.1,\n","        'lr': 1e-3,\n","        'epochs': 100,\n","        'warmup_steps': 20,\n","        'output_dir': './'\n","    }\n","    # Spawn processes (use nprocs=None to use all devices; in notebooks may still run single process)\n","    xmp.spawn(_mp_fn, args=(flags,), nprocs=None, start_method='fork')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"GL5-59BA-afg"},"outputs":[],"source":["!python shred_tpu.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J1yxIlKzwr2j"},"outputs":[],"source":["# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# per singola TPU core:\n","# device = xm.xla_device()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QWX5k6Ixwr2j"},"outputs":[],"source":["Vxtrain = torch.from_numpy(Vxtrain)\n","Vytrain = torch.from_numpy(Vytrain)\n","Vxvalid = torch.from_numpy(Vxvalid)\n","Vyvalid = torch.from_numpy(Vyvalid)\n","Vxtest = torch.from_numpy(Vxtest)\n","Vytest = torch.from_numpy(Vytest)\n","XY = torch.from_numpy(XY)\n","\n","Wx = torch.from_numpy(Wx)\n","Wy = torch.from_numpy(Wy)\n","\n","Vxtrain_POD = torch.from_numpy(Vxtrain_POD)\n","Vxvalid_POD = torch.from_numpy(Vxvalid_POD)\n","Vxtest_POD = torch.from_numpy(Vxtest_POD)\n","\n","Vytrain_POD = torch.from_numpy(Vytrain_POD)\n","Vyvalid_POD = torch.from_numpy(Vyvalid_POD)\n","Vytest_POD = torch.from_numpy(Vytest_POD)\n","\n","MUtrain = torch.from_numpy(MUtrain)\n","MUvalid = torch.from_numpy(MUvalid)\n","MUtest = torch.from_numpy(MUtest)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t-kUXDaswr2k"},"outputs":[],"source":["# Assume mesh_coords is an array of shape (nvelocity, coord_dim) with node coordinates\n","# and idx_sensors is already defined (indices of selected sensors)\n","coord_dim = 2  # e.g. 2 for 2D\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","lag = 50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W2yeVfDMw61t"},"outputs":[],"source":["ntrain = len(idx_train) # number of training trajectories\n","nvalid = len(idx_valid)\n","ntest = len(idx_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ba2JlABYy5gT"},"outputs":[],"source":["n_sensors_choices_per_trajectory = 1\n","sensors_data_train = torch.zeros((n_sensors_choices_per_trajectory * ntrain, ntimes, nsensors))\n","train_hist = torch.zeros((n_sensors_choices_per_trajectory * ntrain * ntimes, nsensors, lag))\n","train_out = torch.zeros((n_sensors_choices_per_trajectory * ntrain * ntimes, kvelocity + 1))\n","sensor_coords_exp = torch.zeros((n_sensors_choices_per_trajectory * ntrain * ntimes, nsensors, coord_dim))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WqSt6nZUwr2k"},"outputs":[],"source":["for i in range(n_sensors_choices_per_trajectory):\n","    sensors_idx_train = np.stack([\n","        np.random.choice(nvelocity, nsensors, replace=False)\n","        for _ in range(n_sensors_choices_per_trajectory * ntrain)\n","    ], axis=0)    # (n_sensors_choices_per_trajectory * ntrain, nsensors)\n","\n","    # sensors_idx_train = indices[idx_train]       # (ntrain,5)\n","    traj_idx_train    = np.arange(ntrain)[:, None, None]   # (ntrain,1,1)\n","    time_idx          = np.arange(ntimes)[None, :, None]   # (1,201,1)\n","    # sensors_idx_train = sensors_idx_train[:, None, :]      # (ntrain,1,5)\n","    sensors_data_train[i*ntrain : (i+1)*ntrain] = Vxtrain[traj_idx_train, time_idx, sensors_idx_train[:, None, :]] # → (ntrain,201,5)\n","\n","    train_hist[i*ntrain*ntimes : (i+1)*ntrain*ntimes] = Padding(sensors_data_train, lag).transpose(1,2) #.to(device) # (N_samples, nsensors, lag)\n","    train_out[i*ntrain*ntimes : (i+1)*ntrain*ntimes] = Padding(torch.cat((Vxtrain_POD, Vytrain_POD, MUtrain[:, :, 0].unsqueeze(2)), 2), 1).squeeze(1) #.to(device) # (N_samples, nvelocity)\n","\n","    sensor_coords_exp[i*ntrain*ntimes : (i+1)*ntrain*ntimes] = torch.from_numpy(np.repeat(XY.numpy()[idx_train][np.arange(ntrain)[:, None, None],\n","                      sensors_idx_train[:, :, None],\n","                      np.arange(coord_dim)[None, None, :]], repeats=ntimes, axis=0)).to(torch.float) #.to(device)\n","# field_coords_exp = torch.from_numpy(np.repeat(XY[idx_train], repeats=ntimes*n_sensors_choices_per_trajectory, axis=0)).to(torch.float) #.to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BmLhwEg0wr2l"},"outputs":[],"source":["# Instantiate datasets and loaders\n","train_dataset = SensorFieldDataset(train_hist, sensor_coords_exp, train_out)\n","# Similarly for valid and test\n","train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0UAgEyrRwr2l"},"outputs":[],"source":["if torch.cuda.device_count() > 1:\n","    print(f\"Using {torch.cuda.device_count()} GPUs\")\n","    model = torch.nn.DataParallel(model)\n","\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bc6u_tvqwr2l"},"outputs":[],"source":["# Instantiate model (using the modified SHRED)\n","# latent_dim chosen as you prefer\n","latent_dim = 128\n","model = SHREDagnostic(coord_dim=coord_dim,\n","              latent_dim=latent_dim,\n","              output_size=train_out.shape[1],\n","              hidden_size=64,\n","              lstm_layers=2,\n","              decoder_sizes=[350, 400, train_out.shape[1]],\n","              dropout=0.1)\n","\n","# Training loop\n","def fit_agnostic(model, train_loader, valid_loader=None, epochs=100, lr=1e-3, loss_fun=torch.nn.MSELoss(), loss_output=mre):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    history = {'train_loss': []}\n","\n","    for epoch in range(1, epochs+1):\n","        model.train()\n","        total_loss = 0.0\n","        for k, (hist, s_coords, target) in enumerate(train_loader):\n","            # print(f\"batch {k}\")\n","            optimizer.zero_grad()\n","            pred = model(hist.to(device, non_blocking=True), s_coords.to(device, non_blocking=True))\n","            loss = loss_fun(pred, target.to(device, non_blocking=True))\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item() * hist.size(0)\n","        avg_loss = total_loss / len(train_loader.dataset)\n","        history['train_loss'].append(avg_loss)\n","        print(f\"Epoch {epoch}/{epochs}, Train Loss: {avg_loss:.6f}\")\n","    return history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7SB1qOZbTpli"},"outputs":[],"source":["def fit_agnostic_tpu(model, train_loader, epochs=100, lr=1e-3):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    history = {'train_loss': []}\n","\n","    for epoch in range(1, epochs+1):\n","        model.train()\n","        total_loss = 0.0\n","        for k, (hist, s_coords, target) in enumerate(train_loader):\n","            # porta tutto su TPU\n","            print(\"batch k\")\n","            hist = hist.to(device, non_blocking=True)\n","            s_coords = s_coords.to(device, non_blocking=True)\n","            target = target.to(device, non_blocking=True)\n","\n","            optimizer.zero_grad()\n","            pred = model(hist, s_coords)\n","            loss = F.mse_loss(pred, target)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item() * hist.size(0)\n","\n","        avg_loss = total_loss / len(train_loader.dataset)\n","        history['train_loss'].append(avg_loss)\n","\n","    return history\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Q9o6ynEUChP"},"outputs":[],"source":["def _mp_fn(rank, flags):\n","    # rank identifica il core, flags può contenere iperparametri\n","    device = xm.xla_device()\n","    # ricrea dataset, modello, loader... ma porta tutto su `device`\n","    model = SHREDagnostic(...).to(device)\n","    train_loader = DataLoader(..., num_workers=0)\n","    history = fit_agnostic_tpu(model, train_loader, epochs=100, lr=1e-3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BCdbyNLzwr2m"},"outputs":[],"source":["# # Run training\n","# history = fit_agnostic(model, train_loader, epochs=400, lr=1e-3)\n","# history = fit_agnostic_tpu(model, train_loader, epochs=400, lr=1e-3)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MXhR9nzawr2m"},"outputs":[],"source":["# Assumendo che `model` sia un'istanza di SHREDagnostic\n","# torch.save(model.state_dict(), \"shred_agnostic.pth\")\n","# model.load_state_dict(torch.load( \"shred_agnostic.pth\", weights_only=True, map_location=torch.device('cpu')))\n","# model.eval()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bk2LuDvzwr2m","colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"status":"error","timestamp":1746063350478,"user_tz":-120,"elapsed":2,"user":{"displayName":"Adriano Racano","userId":"12887391736974890682"}},"outputId":"3bf58ce2-2d30-4a70-e4c6-c00158a5ed0a"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'torch' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-18bf08814031>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"]}],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fle-1K6-wr2q"},"outputs":[],"source":["from matplotlib.colors import Normalize\n","from matplotlib import cm\n","import imageio\n","from mpl_toolkits.axes_grid1 import make_axes_locatable\n","from matplotlib.transforms import Bbox\n","\n","def trajectories_with_sensors(yts, plot, sensors_coordinates, cmap=None, titles=None, fontsize=None, figsize=None, vertical=False, axis=False, save=False, name='gif', vmin=None, vmax=None):\n","    arrays = []\n","    num_sensors = len(sensors_coordinates)\n","\n","    if vmin is not None or vmax is not None:\n","        norm = Normalize(vmin=vmin, vmax=vmax)\n","    else:\n","        norm = None\n","\n","    for i in range(yts[0].shape[0]):\n","        fig, axs = plt.subplots(len(yts) if vertical else 1, 1 if vertical else len(yts), figsize=figsize)\n","        axs = np.atleast_1d(axs)\n","\n","        for j, ax in enumerate(axs):\n","            plt.sca(ax)\n","            plot(yts[j][i], norm=norm)\n","            if j == len(yts) - 2:\n","                for k in range(num_sensors):\n","                    ax.plot(sensors_coordinates[k, 0], sensors_coordinates[k, 1], 'o', mfc='magenta', mec='black', ms=8, mew=1.5)\n","            if titles:\n","                ax.set_title(titles[j], fontsize=fontsize)\n","            if not axis:\n","                ax.axis('off')\n","\n","        plt.colorbar(\n","              cm.ScalarMappable(cmap=cmap, norm=norm),\n","              # ax=axs[0],\n","              cax = fig.add_axes([-0.01, 0.35, 0.01, 0.3]),\n","              location=\"left\",\n","              orientation=\"vertical\",\n","              pad=0.02,           # più piccolo = meno distanza\n","              fraction=0.04,      # più piccolo = colorbar più sottile\n","              aspect=40           # opzionale, controlla il rapporto larghezza/altezza\n","            )\n","\n","        fig.tight_layout()\n","        display(fig)\n","        if save:\n","            fig.canvas.draw()\n","            arrays.append(np.array(fig.canvas.renderer.buffer_rgba()))\n","        plt.close()\n","        clc(wait=True)\n","\n","    if save:\n","        imageio.mimsave(name.replace(\".gif\", \"\") + \".gif\", arrays)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"byVAXrLUwr2m"},"outputs":[],"source":["mult = 1\n","nsensors_test = int(nsensors * mult)\n","whichtrajectory = 4 # np.random.choice(ntest)\n","\n","sensors_idx_test = np.random.choice(nvelocity, nsensors_test, replace=False)\n","# sensors_idx_test = sensors_idx_test[None, :]      # (1, nsensors_test)\n","\n","# sensors_data_test = Vxtest[traj_idx_test, time_idx, sensors_idx_test].unsqueeze(0) (1, ntimes, nsensors_test)\n","sensors_data_test = Vxtest[whichtrajectory, :, sensors_idx_test].unsqueeze(0) # (1, ntimes, nsensors_test)\n","test_hist = Padding(sensors_data_test, lag).transpose(1,2) # (ntimes, lag, nsensors_test)\n","\n","sensors_coords_test = XY[idx_test][whichtrajectory][sensors_idx_test].unsqueeze(0) # (1, nsensors_test, 2)\n","Vtest_POD = model(test_hist.to(device).contiguous(), sensors_coords_test.repeat(ntimes, 1, 1).to(device))[:, :-1]\n","Vtest_hat = torch.sqrt((torch.from_numpy(scalerVx.inverse_transform(Vtest_POD.detach().cpu().numpy()[:,:kvelocity//2])).float() @ Wx).view(1, ntimes, nvelocity)**2 \\\n","                       + \\\n","                       (torch.from_numpy(scalerVy.inverse_transform(Vtest_POD.detach().cpu().numpy()[:,kvelocity//2:])).float() @ Wy).view(1, ntimes, nvelocity)**2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y6uRB1CV5RmQ"},"outputs":[],"source":["# # FOM vs POD RECONSTRUCTION (PLOTS)\n","# import utils.processdata\n","# importlib.reload(utils.processdata)\n","# from utils.processdata import trajectories_with_sensors\n","\n","whichtimes = np.arange(0, 200, 20)\n","\n","plotlist = [Vtest[whichtrajectory, whichtimes], Vtest_hat.numpy()[0, whichtimes], Vtest[whichtrajectory, whichtimes] - Vtest_hat.numpy()[0, whichtimes]]\n","params_geo = MUtest[whichtrajectory, 0, 2:]\n","\n","# redefine plot_v on new triang\n","_, triang = update_coords_and_triang(params_geo)\n","def plot_v(v, triang = triang, norm = None):\n","    if not norm == None:\n","        plt.tricontourf(triang, v, cmap = cmap, norm = norm, levels = 200)\n","    else:\n","        plt.tricontourf(triang, v, cmap = cmap, levels = 200)\n","    plt.gca().set_aspect(\"equal\")\n","    add_zoom(zoom = 1.1)\n","\n","vmin = min(np.abs(plotlist[i]).min() for i in range(len(plotlist)))\n","vmax = max(np.abs(plotlist[i]).max() for i in range(len(plotlist)))\n","\n","trajectories_with_sensors(plotlist, plot_v, sensors_coords_test[0],\n","                          titles = (\"Velocity trajectory\", \"SHRED prediction\", \"Prediction error\"),\n","                          figsize = (10, 5), vertical = False, save = False,\n","                          vmin = vmin, vmax = vmax, cmap = cmap)\n","# trajectories_with_sensors(plotlist, plot_v, idx_sensors, sensors_coords_test[:4][whichtrajectory].detach().cpu().numpy(), titles = (\"Velocity trajectory\", \"SHRED prediction\", \"Prediction error\"), figsize = (10, 5), vertical = False, save = True)"]},{"cell_type":"markdown","metadata":{"id":"oz9Gu0urI6B6"},"source":["### Training sensori 2 (rigenero tutto il dataset con coordinate sensori)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o8-2ETGTJTyq"},"outputs":[],"source":["import torch\n","from copy import deepcopy\n","from IPython.display import clear_output as clc\n","from utils.processdata import mse, mre, num2p\n","\n","import torch.nn.functional as F\n","from utils.processdata import TimeSeriesDataset, Padding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VGruXssUJrky"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qp9hLMKzJTyp"},"outputs":[],"source":["Vxtrain_POD = torch.from_numpy(Vxtrain_POD)\n","Vxvalid_POD = torch.from_numpy(Vxvalid_POD)\n","Vxtest_POD = torch.from_numpy(Vxtest_POD)\n","\n","Vytrain_POD = torch.from_numpy(Vytrain_POD)\n","Vyvalid_POD = torch.from_numpy(Vyvalid_POD)\n","Vytest_POD = torch.from_numpy(Vytest_POD)\n","\n","MUtrain = torch.from_numpy(MUtrain)\n","MUvalid = torch.from_numpy(MUvalid)\n","MUtest = torch.from_numpy(MUtest)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Hz6BQPaJTyp"},"outputs":[],"source":["# BUILD TRAIN, VALIDATION AND TEST DATASETS WITH PADDING\n","\n","from utils.processdata import Padding, TimeSeriesDataset\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","lag = 50\n","\n","# train_data_in = Padding(sensors_data_train, lag).to(device)\n","# valid_data_in = Padding(sensors_data_valid, lag).to(device)\n","# test_data_in = Padding(sensors_data_test, lag).to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TZclyL9J5oT1"},"outputs":[],"source":["# # EXTRACT SENSOR DATA (SKIP THIS CELL IF DATA ALREADY AVAILABLE)\n","# idx_sensors = np.random.choice(nvelocity, size = nsensors, replace = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MjMuOHL7p0SH"},"outputs":[],"source":["# Assume mesh_coords is an array of shape (nvelocity, coord_dim) with node coordinates\n","# and idx_sensors is already defined (indices of selected sensors)\n","coord_dim = 2  # e.g. 2 for 2D\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","lag = 50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6lQgobTZsUCG"},"outputs":[],"source":["# dopo Vxtrain = Vxfull[idx_train]\n","ntrain = len(idx_train)    # es. 64\n","nvalid = len(idx_valid)\n","ntest = len(idx_test)\n","\n","# 1) genera indici random sulle 80 traiettorie\n","indices = np.stack([\n","    np.random.choice(nvelocity, nsensors, replace=False)\n","    for _ in range(ntrajectories)\n","], axis=0)    # (80,5)\n","\n","# 2) ma per train prendi solo quelli di idx_train\n","sensors_idx_train = indices[idx_train]       # (ntrain,5)\n","\n","# 3) ricostruisci un \"traj_idx\" che vada da 0 a ntrain-1\n","traj_idx_train    = np.arange(ntrain)[:, None, None]   # (ntrain,1,1)\n","time_idx          = np.arange(ntimes)[None, :, None]   # (1,201,1)\n","sensors_idx_train = sensors_idx_train[:, None, :]      # (ntrain,1,5)\n","\n","# 4) slicedata su Vxtrain\n","sensors_data_train = torch.from_numpy(\n","    Vxtrain[traj_idx_train, time_idx, sensors_idx_train]\n",").float()   # → (ntrain,201,5)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iWP-01Hc6eAI"},"outputs":[],"source":["train_hist = Padding(sensors_data_train, lag).transpose(1,2) #.to(device) # (N_samples, nsensors, lag)\n","train_out = Padding(torch.cat((Vxtrain_POD, Vytrain_POD, MUtrain[:, :, 0].unsqueeze(2)), 2), 1).squeeze(1) #.to(device) # (N_samples, nvelocity)\n","\n","# valid_hist = Padding(sensors_data_valid, lag).to(device) # (N_samples, lag, nsensors)\n","# valid_out = Padding(torch.cat((Vxvalid_POD, Vyvalid_POD, MUvalid[:, :, 0].unsqueeze(2)), 2), 1).squeeze(1).to(device) # (N_samples, nvelocity)\n","\n","# test_hist = Padding(sensors_data_test, lag).to(device) # (N_samples, lag, nsensors)\n","# test_out = Padding(torch.cat((Vxtest_POD, Vytest_POD, MUtest[:, :, 0].unsqueeze(2)), 2), 1).squeeze(1).to(device) # (N_samples, nvelocity)\n","\n","# Number of samples\n","N_train = train_hist.shape[0]\n","\n","# Expand coords to per-sample\n","sensor_coords_exp = torch.from_numpy(np.repeat(XY[np.arange(ntrajectories)[:, None], indices][idx_train], repeats=ntimes, axis=0)).to(torch.float) #.to(device)\n","field_coords_exp = torch.from_numpy(np.repeat(XY[idx_train], repeats=ntimes, axis=0)).to(torch.float) #.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gO7k0YNZ6g_3"},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","\n","# Define custom dataset\n","class SensorFieldDataset(Dataset):\n","    def __init__(self, hist, sensor_coords, field_coords, targets):\n","        self.hist = hist\n","        self.sensor_coords = sensor_coords\n","        self.field_coords = field_coords\n","        self.targets = targets\n","    def __len__(self):\n","        return self.hist.size(0)\n","    def __getitem__(self, idx):\n","        return (\n","            self.hist[idx],\n","            self.sensor_coords[idx],\n","            self.field_coords[idx],\n","            self.targets[idx]\n","        )\n","\n","# Instantiate datasets and loaders\n","train_dataset = SensorFieldDataset(train_hist, sensor_coords_exp, field_coords_exp, train_out)\n","# Similarly for valid and test\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBZv4QDwJTyq"},"outputs":[],"source":["import importlib\n","import utils.models\n","import utils.processdata\n","importlib.reload(utils.models)\n","importlib.reload(utils.processdata)\n","import utils.models\n","import utils.processdata\n","from utils.models import SHRED, SHREDagnostic, SHREDTransformer, fit_sensors_coords\n","from utils.processdata import Padding, TimeSeriesDataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-8Z8FSjV7K9I"},"outputs":[],"source":["# Instantiate model (using the modified SHRED)\n","# latent_dim chosen as you prefer\n","latent_dim = 128\n","model = SHREDagnostic(coord_dim=coord_dim,\n","              latent_dim=latent_dim,\n","              output_size=train_out.shape[1],\n","              hidden_size=64,\n","              lstm_layers=2,\n","              decoder_sizes=[350, 400, train_out.shape[1]],\n","              dropout=0.1).to(device)\n","\n","# Training loop\n","def fit_agnostic(model, train_loader, valid_loader=None, epochs=100, lr=1e-3, loss_fun=torch.nn.MSELoss(), loss_output=mre):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    history = {'train_loss': []}\n","\n","    for epoch in range(1, epochs+1):\n","        model.train()\n","        total_loss = 0.0\n","        for k, (hist, s_coords, q_coords, target) in enumerate(train_loader):\n","            # print(f\"batch {k}\")\n","            hist, s_coords, q_coords, target = hist.to(device), s_coords.to(device), q_coords.to(device), target.to(device)\n","            optimizer.zero_grad()\n","            # pred = model(hist, s_coords, q_coords)  # (B, nvelocity)\n","            pred = model(hist, s_coords)\n","            # print(pred.shape)\n","            loss = loss_fun(pred, target)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item() * hist.size(0)\n","        avg_loss = total_loss / len(train_loader.dataset)\n","        history['train_loss'].append(avg_loss)\n","        print(f\"Epoch {epoch}/{epochs}, Train Loss: {avg_loss:.6f}\")\n","    return history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zcjwXPG4Ccfa"},"outputs":[],"source":["model.coef_decoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TBa25mJq45wQ"},"outputs":[],"source":["# Run training\n","history = fit_agnostic(model, train_loader, epochs=200, lr=1e-3)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3B6GgleJ3Ukc"},"outputs":[],"source":["# 2) ma per train prendi solo quelli di idx_train\n","sensors_idx_test = indices[idx_test]       # (ntrain,5)\n","\n","# 3) ricostruisci un \"traj_idx\" che vada da 0 a ntrain-1\n","traj_idx_test    = np.arange(ntest)[:, None, None]   # (ntest,1,1)\n","time_idx          = np.arange(ntimes)[None, :, None]   # (1,201,1)\n","sensors_idx_test = sensors_idx_test[:, None, :]      # (ntest,1,5)\n","\n","# 4) slicedata su Vxtrain\n","sensors_data_test = torch.from_numpy(\n","    Vxtest[traj_idx_test, time_idx, sensors_idx_test]\n",").float()   # → (ntest,201,5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cqRvP6_SOE1n"},"outputs":[],"source":["test_hist = Padding(sensors_data_test, lag).transpose(1,2).to(device).contiguous() # (N_samples, lag, nsensors)\n","test_out = Padding(torch.cat((Vxtest_POD, Vytest_POD, MUtest[:, :, 0].unsqueeze(2)), 2), 1).squeeze(1) # .to(device) # (N_samples, nvelocity)\n","\n","sensor_coords_exp_test = torch.from_numpy(np.repeat(XY[np.arange(ntrajectories)[:, None], indices][idx_test], repeats=ntimes, axis=0)).to(torch.float) #.to(device)\n","field_coords_exp_test = torch.from_numpy(np.repeat(XY[idx_test], repeats=ntimes, axis=0)).to(torch.float) #.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yNX5_mmXOspS"},"outputs":[],"source":["del test_out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Dx6JRvFQx8u"},"outputs":[],"source":["N_test = sensor_coords_exp_test.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tOZDHBXOMxFH"},"outputs":[],"source":["Vtest_POD = model(test_hist[:N_test].to(device), sensor_coords_exp_test[:N_test].to(device))[:, :-1]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y9WIgyxWS5zA"},"outputs":[],"source":["Wx = torch.from_numpy(Wx)\n","Wy = torch.from_numpy(Wy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"588fagsaWwN4"},"outputs":[],"source":["Vxtest_hat = torch.from_numpy(scalerVx.inverse_transform(Vtest_POD.detach().cpu().numpy()[:,:kvelocity//2])).to(torch.float32) @ Wx\n","Vytest_hat = torch.from_numpy(scalerVy.inverse_transform(Vtest_POD.detach().cpu().numpy()[:,kvelocity//2:])).to(torch.float32) @ Wy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iY9jvKV0SHC0"},"outputs":[],"source":["# Vtest_hat = torch.zeros(Ntest, ntimes, nvelocity)\n","# Vtest_hat[:, :, 0 : nvelocity : 2] = Vxtest_hat.reshape(ntest, ntimes, nvelocity//2)\n","# Vtest_hat[:, :, 1 : nvelocity : 2] = Vytest_hat.reshape(ntest, ntimes, nvelocity//2)\n","Vtest_hat = torch.sqrt(Vxtest_hat.view(ntest, ntimes, nvelocity)**2 + Vytest_hat.view(ntest, ntimes, nvelocity)**2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XwEjXLHTX3TE"},"outputs":[],"source":["# sensors_coords_test = XY[idx_test][:, idx_sensors]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KGcDX68976tS"},"outputs":[],"source":["sensors_coords_test = XY[np.arange(ntrajectories)[:, None], indices][idx_test]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n-w8BvFiXywz"},"outputs":[],"source":["# FOM vs POD RECONSTRUCTION (PLOTS)\n","\n","from utils.processdata import trajectories_with_sensors\n","\n","whichtrajectory = 2\n","whichtimes = np.arange(0, 200, 10)\n","\n","plotlist = [Vtest[whichtrajectory, whichtimes], Vtest_hat[whichtrajectory, whichtimes], Vtest[whichtrajectory, whichtimes] - Vtest_hat.numpy()[whichtrajectory, whichtimes]]\n","params_geo = MUtest[whichtrajectory, 0, 2:]\n","\n","plotlist = [Vtest[whichtrajectory, whichtimes], Vtest_hat[whichtrajectory, whichtimes], Vtest[whichtrajectory, whichtimes] - Vtest_hat.numpy()[whichtrajectory, whichtimes]]\n","\n","\n","# redefine plot_v on new triang\n","_, triang = update_coords_and_triang(params_geo)\n","def plot_v(v, triang = triang):\n","    plt.tricontourf(triang, v, cmap = cmap, levels = 200)\n","    plt.gca().set_aspect(\"equal\")\n","    add_zoom(zoom = 1.3)\n","\n","vmin = min(np.abs(plotlist[i]).min() for i in range(len(plotlist)))\n","vmax = max(np.abs(plotlist[i]).max() for i in range(len(plotlist)))\n","\n","trajectories_with_sensors(plotlist, plot_v, indices[idx_test][:4][whichtrajectory], sensors_coords_test[:4][whichtrajectory], titles = (\"Velocity trajectory\", \"SHRED prediction\", \"Prediction error\"), figsize = (10, 5), vertical = False, save = True)\n","# trajectories_with_sensors(plotlist, plot_v, idx_sensors, sensors_coords_test[:4][whichtrajectory].detach().cpu().numpy(), titles = (\"Velocity trajectory\", \"SHRED prediction\", \"Prediction error\"), figsize = (10, 5), vertical = False, save = True)"]},{"cell_type":"markdown","metadata":{"id":"fEn9S8NaFzh7"},"source":["### Training sensors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WH0rOlQpFzh8"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5XqQYe9NFzh9"},"outputs":[],"source":["# Vxtrain_POD = torch.from_numpy(Vxtrain_POD).to(device)\n","# Vytrain_POD = torch.from_numpy(Vytrain_POD).to(device)\n","# MUtrain = torch.from_numpy(MUtrain).to(device)\n","# # sensors_coords_new = torch.from_numpy(sensors_coords_new).to(device)\n","# XY = torch.from_numpy(XY).to(device)\n","# Vxtrain = torch.from_numpy(Vxtrain).to(device)\n","# Vxvalid = torch.from_numpy(Vxvalid).to(device)\n","# Vxtest = torch.from_numpy(Vxtest).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V8tzECDnrz3a"},"outputs":[],"source":["# Vxtrain_POD = Vxtrain_POD.to(device)\n","# Vytrain_POD = Vytrain_POD.to(device)\n","# MUtrain = MUtrain.to(device)\n","# # sensors_coords_new = torch.from_numpy(sensors_coords_new).to(device)\n","# XY = XY.to(device)\n","# Vxtrain = Vxtrain.to(device)\n","# Vxvalid = Vxvalid.to(device)\n","# Vxtest = Vxtest.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ItSkb2teFzh8","colab":{"base_uri":"https://localhost:8080/","height":331},"executionInfo":{"status":"error","timestamp":1746063350583,"user_tz":-120,"elapsed":7,"user":{"displayName":"Adriano Racano","userId":"12887391736974890682"}},"outputId":"e831be61-6454-4f51-f3c2-13b6f83b1edd"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'utils'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-7bf6cd11fc38>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import utils.models\n","import utils.processdata"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f_o-6MnHFzh7"},"outputs":[],"source":["import importlib\n","importlib.reload(utils.models)\n","importlib.reload(utils.processdata)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nFelUa2hFzh8"},"outputs":[],"source":["from utils.models import SHRED, SHREDTransformer, SHREDConcat, SHREDPerceiverSpatial\n","from utils.processdata import Padding, TimeSeriesDataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8MKQ3MxbkvQs"},"outputs":[],"source":["d = 2 # 2D"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N69tSDASFzh9"},"outputs":[],"source":["# Le posizioni dei sensori sono variabili trainabili\n","sensors_coords = torch.rand(nsensors, d, device=device, requires_grad=True)\n","sensors_coords.data.mul_(torch.tensor([L, H], device=device, dtype=torch.float32))\n","\n","# Inizializza il modello SHRED (o SHREDTransformer)\n","# Nel tuo caso il modello in input prende la time series dei sensori: shape (ntraj, ntimes, nsensors)\n","# e produce un output (ad es., dimensione kvelocity+1)\n","\n","model = SHRED(input_size=nsensors * (d+1), output_size=kvelocity + 1, hidden_size=64, hidden_layers=2,\n","              decoder_sizes=[350, 400], dropout=0.1).to(device)\n","# model = SHREDConcat(nsensors, coord_pe_dim = 2*D, output_size=kvelocity + 1, hidden_size=64, hidden_layers=2,\n","#               decoder_sizes=[350, 400], dropout=0.1).to(device)\n","# model = SHREDPerceiverSpatial(nsensors, coord_dim = 2 * D, d_model = 64, output_size=kvelocity + 1, hidden_size=64, hidden_layers=2,\n","#               decoder_sizes=[350, 400], dropout=0.1).to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VgKG4WQLMWrg"},"outputs":[],"source":["plt.figure()\n","scatter_array(naca0012_airfoil_coords, s = 0.1)\n","scatter_array(sensors_coords.detach().cpu().numpy(), s = 50)\n","plt.plot([0, L, L, 0, 0], [0, 0, H, H, 0])\n","add_zoom()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eMpBd09uGDzU"},"outputs":[],"source":["# sensor_encodings = fourier_encode(sensors_coords, B).clone().detach().to(device).requires_grad_(True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IZR3ImCXRNjS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vZWbe6R2lJaN"},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader\n","from copy import deepcopy\n","from IPython.display import clear_output as clc\n","from utils.processdata import mse, mre, num2p\n","\n","import torch.nn.functional as F\n","from utils.processdata import TimeSeriesDataset, Padding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BuUg2MiZnk4C"},"outputs":[],"source":["sensor_interpolator = SensorDataInterpolator(B.to(device)).to(device)  # o device appropriato\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZpJfHDIolV0E"},"outputs":[],"source":["lag = 50\n","# optim_cls=torch.optim.Adam\n","lr_shred=1e-3\n","lr_sensors=0.05\n","batch_size = ntimes * 2 # deve essere multiplo o divisore di ntimes\n","batch_size = 67\n","epochs = 2000\n","print_every_epochs = 5\n","update_sensors_every_steps = 20\n","scatter_sensors_every_steps = epochs\n","\n","loss_fun = mse\n","loss_output = mre\n","formatter = num2p\n","\n","train_error_list = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XzM1UveDlx8j"},"outputs":[],"source":["# Preinizializza l'ottimizzatore con i parametri del modello e anche sensors_coords\n","# Definisci due ottimizzatori:\n","optimizer_model = torch.optim.Adam(model.parameters(), lr=lr_shred)           # per il modello SHRED\n","optimizer_sensors = torch.optim.Adam([sensors_coords], lr=lr_sensors)         # per le coordinate dei sensori"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mzaqi5d1n3DK"},"outputs":[],"source":["node_encodings_train = fourier_encode(XY[idx_train].view(-1, XY.shape[-1]), B).view(len(idx_train), nvelocity, -1).to(device)\n","node_encodings_valid = fourier_encode(XY[idx_valid].view(-1, XY.shape[-1]), B).view(len(idx_valid), nvelocity, -1).to(device)\n","node_encodings_test = fourier_encode(XY[idx_test].view(-1, XY.shape[-1]), B).view(len(idx_test), nvelocity, -1).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fCfCuPkEFzh-"},"outputs":[],"source":["train_data_out = Padding(torch.cat((Vxtrain_POD, Vytrain_POD, MUtrain[:,:,0].unsqueeze(2)), 2), 1).squeeze(1).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9iXx68cA_47t"},"outputs":[],"source":["sensors_data_train = sensor_interpolator(sensors_coords, Vxtrain, node_encodings_train)  # shape (ntraj, ntimes, nsensors)\n","sensors_data_valid = sensor_interpolator(sensors_coords, Vxvalid, node_encodings_valid)  # shape (ntraj, ntimes, nsensors)\n","sensors_data_test = sensor_interpolator(sensors_coords, Vxtest, node_encodings_test)  # shape (ntraj, ntimes, nsensors)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x-WFpPZZEXsm"},"outputs":[],"source":["train_dataset = TimeSeriesDataset(Padding(sensors_data_train, lag).to(device), train_data_out)\n","test_data_in = Padding(sensors_data_test, lag).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dt_WrMwRsePd"},"outputs":[],"source":["Y_loader = DataLoader(train_data_out, shuffle=False, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4FaEXibspEWf"},"outputs":[],"source":["sensors_history = [sensors_coords.detach().cpu().numpy()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9k0LYEDFWAoK"},"outputs":[],"source":["# sensors_coords_train = np.tile(XY[idx_train][:, idx_sensors], reps = (ntimes, 1, 1))\n","# sensors_coords_train = torch.from_numpy(sensors_coords_train).to(torch.float32).to(device)\n","\n","# sensors_coords_valid = np.tile(XY[idx_valid][:, idx_sensors], reps = (ntimes, 1, 1))\n","# sensors_coords_valid = torch.from_numpy(sensors_coords_valid).to(torch.float32).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lqe6Ep_cWAoL"},"outputs":[],"source":["# dataset = list(zip(sensors_coords_train, train_data_in, train_data_out))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-pcRkC6CqYK6"},"outputs":[],"source":["coords = sensors_coords.unsqueeze(0).unsqueeze(0)\n","coords_exp = coords.expand(len(idx_train) * ntimes, lag, nsensors, d)\n","train_data = torch.cat([coords_exp, train_dataset.X.unsqueeze(-1)], dim=-1)\n","train_data = train_data.view(len(idx_train) * ntimes, lag,\n","                      nsensors * (d + 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wokfHHacsJcd"},"outputs":[],"source":["train_data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-oGx4iawxauC"},"outputs":[],"source":["X_batch.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":4,"status":"error","timestamp":1746063350765,"user":{"displayName":"Adriano Racano","userId":"12887391736974890682"},"user_tz":-120},"id":"7aKnadaxsb2c","outputId":"d5702b81-e8f2-4db9-d4bb-bea37c962e61"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'epochs' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-88f1a7bb598d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# print(f\"epoch {epoch}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"]}],"source":["# Inizializza la cache per memorizzare i batch calcolati\n","batch_cache = {}\n","\n","global_step = 0\n","for epoch in range(1, epochs + 1):\n","    # print(f\"epoch {epoch}\")\n","    for batch_idx, Y_batch in enumerate(Y_loader):\n","        model.train()\n","\n","        # # Calcola l'indice e la finestra temporale per il batch corrente (backup)\n","        # traj_idx = batch_idx * batch_size // ntimes\n","        # start_time = (batch_idx % (ntimes // batch_size)) * batch_size\n","        # end_time = start_time + batch_size\n","\n","        # Calcola l'indice e la finestra temporale per il batch corrente\n","        traj_idx = [batch_idx * batch_size // ntimes] if batch_size < ntimes else np.arange(batch_idx * batch_size // ntimes, (batch_idx + 1) * batch_size // ntimes).tolist()\n","        start_time = (batch_idx % (ntimes // batch_size) if (ntimes // batch_size != 0) else 0) * batch_size\n","        end_time = start_time + batch_size\n","\n","        # Definisci una chiave univoca per questo batch\n","        key = (traj_idx[-1], start_time, end_time)\n","        # print(key)\n","\n","        if global_step % update_sensors_every_steps == 0 or key not in batch_cache:\n","            # print(f\"Epoch {epoch}: interpolating...\")\n","            sensors_coords = torch.rand(nsensors, d, device=device, requires_grad=False)\n","            sensors_coords.data.mul_(torch.tensor([L, H], device=device, dtype=torch.float32))\n","            sensor_data = sensor_interpolator(\n","                sensors_coords,\n","                Vxtrain[traj_idx][:, start_time:end_time],\n","                node_encodings_train[traj_idx]\n","            )\n","            sensor_encodings = fourier_encode(sensors_coords, B).detach()\n","            # print(sensor_data.shape)\n","            X_batch = Padding(sensor_data, lag).to(device)\n","            # print(X_batch.shape)\n","            batch_cache[key] = X_batch  # salva X_batch nel cache con grafo attivo\n","        else:\n","            # Usa il valore in cache ma \"detach\" per non propagare i gradienti\n","            X_batch = batch_cache[key].detach()\n","            # X_batch = gate_gradient(batch_cache[key].clone(), 0.0)\n","\n","        # Concatenazione con coordinate sensori\n","        coords = sensors_coords.unsqueeze(0).unsqueeze(0)\n","        coords_exp = coords.expand(batch_size, lag, nsensors, d)\n","        X_batch = torch.cat([coords_exp, X_batch.unsqueeze(-1)], dim=-1)\n","        X_batch = X_batch.view(batch_size,\n","                              lag,\n","                              nsensors * (d + 1))\n","\n","        # Procedi con il resto del forward e backward\n","        optimizer_model.zero_grad()\n","        # optimizer_sensors.zero_grad()\n","        outputs = model(X_batch)\n","        loss = loss_fun(outputs, Y_batch)\n","        loss.backward()\n","        optimizer_model.step()\n","\n","    # if global_step % update_sensors_every_steps == 0:\n","    #     optimizer_sensors.step()\n","    #     # Applica il reflection in-place sui sensori\n","    #     # sensors_coords.data = reflect_coords(sensors_coords.data, L, H)\n","    #     sensors_coords.data = reflect_with_grad_flip(sensors_coords.data, L, H)\n","\n","    global_step += 1\n","\n","    if global_step % update_sensors_every_steps == 0:\n","        # sensors_history.append(fourier_decode(sensor_encodings.cpu()).detach().cpu().numpy())\n","        sensors_history.append(sensors_coords.detach().cpu().numpy())\n","    # Logging e validazione\n","    if epoch % print_every_epochs == 0:\n","        model.eval()\n","        with torch.no_grad():\n","            train_error = loss_output(train_dataset.Y, model(train_data))\n","            train_error_list.append(train_error)\n","        print(f\"Epoch {epoch}: Training loss = {formatter(train_error_list[-1])}\")\n","\n","    if epoch % scatter_sensors_every_steps == 0:\n","        print(sensors_coords.detach().cpu().numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_1tLqPXsxxLb"},"outputs":[],"source":["model.mix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hvTJqCbVvFwB"},"outputs":[],"source":["colors = [\n","    'red',\n","    'blue',\n","    'green',\n","    'orange',\n","    'purple',\n","    'cyan',\n","    'magenta',\n","    'yellow',\n","    'brown',\n","    'gray'\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9i9UlSRr0i2l"},"outputs":[],"source":["plt.figure()\n","\n","# Airfoil senza label\n","scatter_array(naca0012_airfoil_coords, s=0.1, label='_nolegend_')\n","\n","# Dominio senza label\n","plt.plot([0, L, L, 0, 0], [0, 0, H, H, 0], label='_nolegend_')\n","\n","# Numero di sensori\n","num_sensors = len(sensors_history[0])\n","\n","for i in range(num_sensors):\n","    traj = np.array([step[i] for step in sensors_history])\n","\n","    # Linea della traiettoria\n","    plt.plot(traj[:, 0], traj[:, 1], color=colors[i], label=f'Sensor {i+1}', linewidth = 1)\n","\n","    # Marker inizio con colore della linea\n","    plt.scatter(traj[0, 0], traj[0, 1], color=colors[i], edgecolors='k', marker='o', s=100, label='_nolegend_')\n","\n","    # Marker fine con colore della linea\n","    plt.scatter(traj[-1, 0], traj[-1, 1], color=colors[i], edgecolors='k', marker='X', s=100, label='_nolegend_')\n","\n","# Aggiungi marker \"Start\" e \"End\" alla legenda con solo bordo nero\n","plt.scatter([], [], facecolors='none', edgecolors='k', marker='o', s=100, label='Start')\n","plt.scatter([], [], facecolors='none', edgecolors='k', marker='X', s=100, label='End')\n","\n","plt.title(\"Traiettorie dei sensori\")\n","plt.xlabel(\"X\")\n","plt.ylabel(\"Y\")\n","plt.grid(True)\n","plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n","# plt.tight_layout()\n","add_zoom()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"wThwpcxT7Po5"},"source":["### Positional encoding 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k9-nyluh7Po6"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8nBOZOiVAL8e"},"outputs":[],"source":["traj_id = [20]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9jkd_lxQ7Po7"},"outputs":[],"source":["train_trajectories = len(idx_train)\n","train_trajectories"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zAJeTR_e7YUa"},"outputs":[],"source":["!pip install pydoe"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_sUmIlX28RoC"},"outputs":[],"source":["from pyDOE import lhs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GpC83Oid8SSU"},"outputs":[],"source":["nsensors = 2000"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DrprgfBI7Po7"},"outputs":[],"source":["# sensors_coords_new = np.concatenate((np.random.rand(nsensors, 1) * (xmax - xmin) + xmin, np.random.rand(nsensors, 1) * (ymax - ymin) + ymin), 1, dtype = np.float32)\n","sensors_coords_new = lhs(2, nsensors) * [L, H]\n","sensors_coords_new = torch.from_numpy(sensors_coords_new).to(torch.float32)\n","# XY = torch.from_numpy(XY)\n","# Vxtrain = torch.from_numpy(Vxtrain)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lb52SdCP7Po7"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","\n","# --------------------------------------------------\n","# 1. Definizione della funzione di Fourier Positional Encoding\n","# --------------------------------------------------\n","def fourier_encode(x, B):\n","    \"\"\"\n","    Applica il positional encoding Fourier alle coordinate.\n","\n","    Parametri:\n","      - x: tensor di shape (n, d) (ad esempio, coordinate spaziali)\n","      - B: tensor di shape (d, D) contenente le frequenze.\n","\n","    Restituisce:\n","      - encoding: tensor di shape (n, 2*D) ottenuto concatenando sin(xB) e cos(xB).\n","    \"\"\"\n","    # Proiezione: x @ B produce un tensore di shape (n, D)\n","    x_proj = 2 * torch.pi * x @ B\n","    return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n","\n","# --------------------------------------------------\n","# 2. Setup dei parametri e degli input\n","# --------------------------------------------------\n","d = 2   # dimensione originale delle coordinate (x, y)\n","D = 16  # dimensione scelta per la proiezione (puoi variare questo parametro)\n","\n","# Matrice di frequenze per il Fourier encoding (può essere fissata oppure resa learnable)\n","B = torch.randn(d, D).to(device)\n","\n","# --------------------------------------------------\n","# 3. Calcolo degli encoding Fourier per i nodi e per i sensori\n","# --------------------------------------------------\n","# Calcolo dell'encoding per i sensori: shape (nsensors, 2*D)\n","sensor_encodings = fourier_encode(sensors_coords_new, B)  # comune a tutte le traiettorie\n","\n","# Calcolo dell'encoding per i nodi per tutte le traiettorie.\n","# Risultato atteso: (ntraj, nvelocity, 2*D)\n","# Possiamo calcolarlo in modo vettorizzato:\n","\n","node_encodings_train = fourier_encode(XY[idx_train][traj_id].view(-1, d), B)\n","# node_encodings_train = node_encodings_train.view(len(idx_train), nvelocity, 2 * D)\n","node_encodings_train = node_encodings_train.view(len([traj_id]), nvelocity, 2 * D)\n","\n","# node_encodings_valid = fourier_encode(XY[idx_valid].view(-1, d), B)\n","# node_encodings_valid = node_encodings_valid.view(len(idx_valid), nvelocity, 2 * D)\n","\n","# node_encodings_test = fourier_encode(XY[idx_test].view(-1, d), B)\n","# node_encodings_test = node_encodings_test.view(len(idx_test), nvelocity, 2 * D)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rPIVVd2t7Po8"},"outputs":[],"source":["# --------------------------------------------------\n","# 4. Calcolo dei pesi di similarità e interpolazione\n","# --------------------------------------------------\n","# Per ogni traiettoria, calcoliamo la similarità fra i sensori e i nodi.\n","# Usiamo broadcasting per ottenere in una sola operazione:\n","#\n","#   sensor_encodings: (nsensors, 2*D)\n","#   node_encodings: (ntraj, nvelocity, 2*D)\n","#\n","# Vogliamo ottenere similarity: (ntraj, nsensors, nvelocity)\n","# facendo, per ogni traiettoria i e per ogni sensore j,\n","#   similarity[i,j] = sensor_encodings[j] · node_encodings[i].T\n","sensor_encodings_expanded = sensor_encodings.unsqueeze(0)  # shape: (1, nsensors, 2*D)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V04pIUOQ7Po8"},"outputs":[],"source":["# Trasponiamo l'encoding dei nodi per il prodotto scalare:\n","node_encodings_t = node_encodings_train  # shape: (ntraj, nvelocity, 2*D)\n","similarity = torch.matmul(sensor_encodings_expanded, node_encodings_t.transpose(1,2))\n","# similarity: (ntraj, nsensors, nvelocity)\n","\n","# Otteniamo i pesi (softmax sul nodo-dimensione, ovvero dim=2)\n","weights = F.softmax(similarity, dim=2)  # shape: (ntraj, nsensors, nvelocity)\n","\n","# Ora, per ogni traiettoria e per ogni timestep, eseguiamo la media pesata dei valori dei nodi.\n","# Vxtrain ha shape: (ntraj, ntimes, nvelocity)\n","# Per eseguire la moltiplicazione, trasponiamo weights in modo che abbiano shape (ntraj, nvelocity, nsensors)\n","weights_t = weights.transpose(1,2)  # shape: (ntraj, nvelocity, nsensors)\n","\n","sensors_data_train = torch.matmul(Vxtrain[traj_id], weights_t)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N72wQSjB7Po9"},"outputs":[],"source":["scatter_array(naca0012_coords, s = 0.1)\n","scatter_array(sensors_coords_new, s = 50)\n","add_zoom()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CwOuyDvm7Po-","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"error","timestamp":1746063350774,"user_tz":-120,"elapsed":5,"user":{"displayName":"Adriano Racano","userId":"12887391736974890682"}},"outputId":"214bb7c4-3814-475b-fb1f-56381891fbb7"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'np' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-792e08314e77>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# whichtrajectory = 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mwhichtrajectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mwhichtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m trajectory_with_sensors(Vxtrain[whichtrajectory, whichtimes],\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}],"source":["# TRAJECTORY WITH SENSORS (PLOT)\n","import matplotlib as mpl\n","\n","def trajectory_with_sensors(vt, params_geo, sensors_coordinates, sensors_values, title = None):\n","    \"\"\"\n","    Velocity trajectory with sensors\n","    Input: velocity trajectory with dimension (ntimes, nvelocity), geometric parameters and and the selected sensor indices\n","    \"\"\"\n","    # redefine plot_v on new triang\n","    coords, triang = update_coords_and_triang(params_geo)\n","    norm = mpl.colors.Normalize(vmin = vt.min().item(), vmax = vt.max().item())\n","    def plot_v(v, triang = triang):\n","        plt.tricontourf(triang, v, cmap = cmap, levels = 200, norm = norm)\n","        plt.gca().set_aspect(\"equal\")\n","        add_zoom(zoom = 1.3)\n","\n","    # sensors_coordinates = coords[idx_sensors, :2]\n","    nsensors = sensors_coordinates.shape[0]\n","\n","    for i in range(vt.shape[0]):\n","        plt.figure(figsize=(10,10))\n","        # plot_v(vt[i])\n","        for k in np.arange(nsensors):\n","            plt.scatter(sensors_coordinates[k, 0], sensors_coordinates[k, 1], c = sensors_values[i, k],\n","                        facecolors='none',   # interno trasparente\n","                        edgecolors='white',\n","                        marker = 'o', norm = norm, s = 100, cmap = cmap) # , mec = 'black', ms = 8, mew = 1.5)\n","        plt.xlim((-0.1,10.1))\n","        plt.title(title)\n","        plt.axis('off')\n","        display(plt.gcf())\n","        plt.close()\n","        clc(wait=True)\n","\n","# whichtrajectory = 3\n","whichtrajectory = 0\n","whichtimes = np.arange(0, 200, 10)\n","\n","trajectory_with_sensors(Vxtrain[whichtrajectory, whichtimes],\n","                        MUtrain[whichtrajectory, 0, 2:],\n","                        sensors_coordinates=sensors_coords_new,\n","                        sensors_values= sensors_data_train.detach().numpy()[whichtrajectory, whichtimes],\n","                        title = \"Velocity trajectory with sensors\")"]},{"cell_type":"markdown","metadata":{"id":"OKXbG-y38BBk"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u6WTPLW-3OFD"},"outputs":[],"source":["np.random.seed(41)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j0eiRZ0T8BBg"},"outputs":[],"source":["# # Simuliamo 5 sensori, ma ad ogni training step le loro coordinate cambiano\n","nsensors = 5\n","[xmin, xmax, ymin, ymax] = geometry = [0, 10, 0, 4]\n","# sensors_coords_new = np.concatenate((np.random.rand(nsensors, 1) * (xmax - xmin) + xmin, np.random.rand(nsensors, 1) * (ymax - ymin) + ymin), 1, dtype = np.float32)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tXiCTq_SDvOw"},"outputs":[],"source":["# EXTRACT SENSOR DATA (SKIP THIS CELL IF DATA ALREADY AVAILABLE)\n","idx_sensors = np.random.choice(nvelocity, size = nsensors, replace = False)\n","\n","sensors_data_train = Vxtrain[:,:,idx_sensors]\n","sensors_data_valid = Vxvalid[:,:,idx_sensors]\n","sensors_data_test = Vxtest[:,:,idx_sensors]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4KyhOB3I8BBl"},"outputs":[],"source":["# # sensors_data_train = torch.from_numpy(sensors_data_train)\n","# # sensors_data_valid = torch.from_numpy(sensors_data_valid)\n","# # sensors_data_test = torch.from_numpy(sensors_data_test)\n","\n","# # Vxtrain_POD = torch.from_numpy(Vxtrain_POD)\n","# Vxvalid_POD = torch.from_numpy(Vxvalid_POD)\n","# Vxtest_POD = torch.from_numpy(Vxtest_POD)\n","\n","# # Vytrain_POD = torch.from_numpy(Vytrain_POD)\n","# Vyvalid_POD = torch.from_numpy(Vyvalid_POD)\n","# Vytest_POD = torch.from_numpy(Vytest_POD)\n","\n","# # MUtrain = torch.from_numpy(MUtrain)\n","# MUvalid = torch.from_numpy(MUvalid)\n","# MUtest = torch.from_numpy(MUtest)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1kTVvCM9jKQL"},"outputs":[],"source":["sensors_data_train = torch.from_numpy(sensors_data_train)\n","sensors_data_valid = torch.from_numpy(sensors_data_valid)\n","sensors_data_test = torch.from_numpy(sensors_data_test)\n","\n","Vxtrain_POD = torch.from_numpy(Vxtrain_POD)\n","Vxvalid_POD = torch.from_numpy(Vxvalid_POD)\n","Vxtest_POD = torch.from_numpy(Vxtest_POD)\n","\n","Vytrain_POD = torch.from_numpy(Vytrain_POD)\n","Vyvalid_POD = torch.from_numpy(Vyvalid_POD)\n","Vytest_POD = torch.from_numpy(Vytest_POD)\n","\n","MUtrain = torch.from_numpy(MUtrain)\n","MUvalid = torch.from_numpy(MUvalid)\n","MUtest = torch.from_numpy(MUtest)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"odw1jwmbA7Nn"},"outputs":[],"source":["# BUILD TRAIN, VALIDATION AND TEST DATASETS WITH PADDING\n","\n","from utils.processdata import Padding, TimeSeriesDataset\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","lag = 50\n","\n","train_data_in = Padding(sensors_data_train, lag).to(device)\n","valid_data_in = Padding(sensors_data_valid, lag).to(device)\n","test_data_in = Padding(sensors_data_test, lag).to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dovxl4nh8BBl"},"outputs":[],"source":["train_data_out = Padding(torch.cat((Vxtrain_POD, Vytrain_POD, MUtrain[:,:,0].unsqueeze(2)), 2), 1).squeeze(1).to(device)\n","valid_data_out = Padding(torch.cat((Vxvalid_POD, Vyvalid_POD, MUvalid[:,:,0].unsqueeze(2)), 2), 1).squeeze(1).to(device)\n","test_data_out = Padding(torch.cat((Vxtest_POD, Vytest_POD, MUtest[:,:,0].unsqueeze(2)), 2), 1).squeeze(1).to(device)\n","\n","train_dataset = TimeSeriesDataset(train_data_in, train_data_out)\n","valid_dataset = TimeSeriesDataset(valid_data_in, valid_data_out)\n","test_dataset = TimeSeriesDataset(test_data_in, test_data_out)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"teNf6HY3dMEl"},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader\n","from copy import deepcopy\n","from IPython.display import clear_output as clc\n","from utils.processdata import mse, mre, num2p\n","\n","import torch.nn.functional as F\n","from utils.processdata import TimeSeriesDataset, Padding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gKJ4ZNl4QvOt","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"error","timestamp":1746063352566,"user_tz":-120,"elapsed":1765,"user":{"displayName":"Adriano Racano","userId":"12887391736974890682"}},"outputId":"bf15cc84-803b-4cc6-cd89-f889e6ea367c"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'mse' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-66a488b08184>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m def fit_with_memory_monitoring(model, train_dataset, valid_dataset, batch_size=64, epochs=1000,\n\u001b[0;32m----> 6\u001b[0;31m                                \u001b[0moptim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmre\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                                formatter=num2p, verbose=True, patience=100, monitor_interval=10, device=\"cuda\"):\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'mse' is not defined"]}],"source":["import torch\n","from torch.utils.data import DataLoader\n","from copy import deepcopy\n","\n","def fit_with_memory_monitoring(model, train_dataset, valid_dataset, batch_size=64, epochs=1000,\n","                               optim=torch.optim.Adam, lr=1e-3, loss_fun=mse, loss_output=mre,\n","                               formatter=num2p, verbose=True, patience=100, monitor_interval=10, device=\"cuda\"):\n","    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n","    optimizer = optim(model.parameters(), lr=lr)\n","\n","    train_error_list = []\n","    valid_error_list = []\n","    patience_counter = 0\n","    best_params = deepcopy(model.state_dict())\n","    global_step = 0\n","\n","    for epoch in range(1, epochs + 1):\n","\n","        for k, data in enumerate(train_loader):\n","            model.train()\n","            optimizer.zero_grad()\n","            outputs = model(data[0].to(device))\n","            loss = loss_fun(outputs, data[1].to(device))\n","            loss.backward()\n","            optimizer.step()\n","            global_step += 1\n","\n","        model.eval()\n","        with torch.no_grad():\n","            train_error = loss_output(train_dataset.Y.to(device), model(train_dataset.X.to(device)))\n","            valid_error = loss_output(valid_dataset.Y.to(device), model(valid_dataset.X.to(device)))\n","            train_error_list.append(train_error)\n","            valid_error_list.append(valid_error)\n","\n","        if verbose:\n","            print(\"Epoch {:d}: Training loss = {} \\t Validation loss = {}\".format(\n","                epoch, formatter(train_error_list[-1]), formatter(valid_error_list[-1])\n","            ))\n","\n","            # Monitoraggio della memoria ogni 'monitor_interval' epoche\n","            if epoch % monitor_interval == 0:\n","                mem_alloc = torch.cuda.memory_allocated(device) / 1024**2\n","                mem_reserved = torch.cuda.memory_reserved(device) / 1024**2\n","                print(\"GPU memory allocated: {:.2f} MB, reserved: {:.2f} MB\".format(mem_alloc, mem_reserved))\n","                # Puoi anche stampare un report più completo se vuoi:\n","                # print(torch.cuda.memory_summary(device=device))\n","\n","        if valid_error == torch.min(torch.tensor(valid_error_list)):\n","            patience_counter = 0\n","            best_params = deepcopy(model.state_dict())\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter == patience:\n","            model.load_state_dict(best_params)\n","            train_error = loss_output(train_dataset.Y.to(device), model(train_dataset.X.to(device)))\n","            valid_error = loss_output(valid_dataset.Y.to(device), model(valid_dataset.X.to(device)))\n","            if verbose:\n","                print(\"Training done: Training loss = {} \\t Validation loss = {}\".format(\n","                    formatter(train_error), formatter(valid_error)\n","                ))\n","            return (torch.tensor(train_error_list).detach().cpu().numpy(),\n","                    torch.tensor(valid_error_list).detach().cpu().numpy())\n","\n","    model.load_state_dict(best_params)\n","    train_error = loss_output(train_dataset.Y.to(device), model(train_dataset.X.to(device)))\n","    valid_error = loss_output(valid_dataset.Y.to(device), model(valid_dataset.X.to(device)))\n","    if verbose:\n","        print(\"Training done: Training loss = {} \\t Validation loss = {}\".format(\n","            formatter(train_error), formatter(valid_error)\n","        ))\n","    return (torch.tensor(train_error_list).detach().cpu().numpy(),\n","            torch.tensor(valid_error_list).detach().cpu().numpy())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dn86TPAv-0vc"},"outputs":[],"source":["mem_alloc = torch.cuda.memory_allocated(device) / 1024**2\n","mem_reserved = torch.cuda.memory_reserved(device) / 1024**2\n","print(\"GPU memory allocated: {:.2f} MB, reserved: {:.2f} MB\".format(mem_alloc, mem_reserved))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UoHHLBmaFi2Y"},"outputs":[],"source":["import importlib\n","import utils.models\n","import utils.processdata\n","importlib.reload(utils.models)\n","importlib.reload(utils.processdata)\n","import utils.models\n","import utils.processdata\n","from utils.models import SHRED, SHREDTransformer, fit_sensors_coords\n","from utils.processdata import Padding, TimeSeriesDataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F2_OVj9HB4Up"},"outputs":[],"source":["sensors_coords_train = np.tile(XY[idx_train][:, idx_sensors], reps = (ntimes, 1, 1))\n","sensors_coords_train = torch.from_numpy(sensors_coords_train).to(torch.float32).to(device)\n","\n","sensors_coords_valid = np.tile(XY[idx_valid][:, idx_sensors], reps = (ntimes, 1, 1))\n","sensors_coords_valid = torch.from_numpy(sensors_coords_valid).to(torch.float32).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N6_41_JCEc4A"},"outputs":[],"source":["dataset = list(zip(sensors_coords_train, train_data_in, train_data_out))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9-XQrppjA7Nn"},"outputs":[],"source":["# SHRED TRAINING (SKIP THIS CELL IF SHRED ALREADY AVAILABLE)\n","\n","from utils.models import SHRED, SHREDTransformer, fit\n","\n","shred = SHRED(nsensors, kvelocity + 1, hidden_size = 64, hidden_layers = 2, decoder_sizes = [350, 400], dropout = 0.1).to(device)\n","train_errors, valid_errors = fit_sensors_coords(shred, train_dataset, valid_dataset, sensors_coords_train, sensors_coords_valid, batch_size = 64, epochs = 1000, lr = 1e-3, verbose = True, patience = 100) # , device = device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uo3btjsfA7No"},"outputs":[],"source":["# # SHRED LOADING\n","\n","# from utils.models import SHRED\n","\n","# shred = SHRED(nsensors, kvelocity + 1, hidden_size = 64, hidden_layers = 2, decoder_sizes = [350, 400], dropout = 0.1).to(device)\n","# shred.load_state_dict(torch.load('FlowAroundObstacle_shred_velocity_paramestimation.pt', weights_only = True, map_location = torch.device(device)));"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YmX6ACfsGv4G"},"outputs":[],"source":["Wx = torch.from_numpy(Wx)\n","Wy = torch.from_numpy(Wy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sOqLWKFCVyiQ"},"outputs":[],"source":["sensors_coords_test = np.tile(XY[idx_test][:, idx_sensors].cpu().numpy(), reps = (ntimes, 1, 1))\n","sensors_coords_test = torch.from_numpy(sensors_coords_test).to(torch.float32).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FEEHhMniA7Np"},"outputs":[],"source":["# SHRED ERRORS ON TEST DATA\n","\n","shred.freeze()\n","\n","test_dataset_out_hat = shred(test_data_in, sensors_coords_test).cpu()\n","\n","alpha_in_test_hat = test_dataset_out_hat[:,-1].reshape(ntest, ntimes)\n","\n","Vtest_POD_hat = test_dataset_out_hat[:,:-1]\n","Vxtest_hat = torch.from_numpy(scalerVx.inverse_transform(Vtest_POD_hat.detach()[:,:kvelocity//2])).to(torch.float32) @ Wx\n","Vytest_hat = torch.from_numpy(scalerVy.inverse_transform(Vtest_POD_hat.detach()[:,kvelocity//2:])).to(torch.float32) @ Wy\n","\n","Vtest_hat = torch.zeros(ntest, ntimes, nvelocity)\n","# Vtest_hat[:, :, 0 : nvelocity : 2] = Vxtest_hat.reshape(ntest, ntimes, nvelocity//2)\n","# Vtest_hat[:, :, 1 : nvelocity : 2] = Vytest_hat.reshape(ntest, ntimes, nvelocity//2)\n","Vtest_hat = torch.sqrt(Vxtest_hat.reshape(ntest, ntimes, nvelocity)**2 + Vytest_hat.reshape(ntest, ntimes, nvelocity)**2)\n","\n","# print(\"Mean relative SHRED prediction error on V: %s\" % num2p(mre(Vtest, Vtest_hat)))\n","# print(\"Mean absolute SHRED prediction error on the angle of attack: %s\" % round(mae(MUtest[:,:,0], alpha_in_test_hat).item(), 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hojkSOE2JISh"},"outputs":[],"source":["# train_dataset_out_hat = model(Padding(sensors_data_train, lag).to(device)).cpu()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V7oxWUk8JN3u"},"outputs":[],"source":["# alpha_in_train_hat = train_dataset_out_hat[:,-1].reshape(ntrain, ntimes)\n","\n","# Vtrain_POD_hat = train_dataset_out_hat[:,:-1]\n","# Vxtrain_hat = torch.from_numpy(scalerVx.inverse_transform(Vtrain_POD_hat[:,:kvelocity//2])) @ Wx\n","# Vytrain_hat = torch.from_numpy(scalerVy.inverse_transform(Vtrain_POD_hat[:,kvelocity//2:])) @ Wy\n","\n","# Vtrain_hat = torch.zeros(ntrain, ntimes, nvelocity)\n","# # Vtest_hat[:, :, 0 : nvelocity : 2] = Vxtest_hat.reshape(ntest, ntimes, nvelocity//2)\n","# # Vtest_hat[:, :, 1 : nvelocity : 2] = Vytest_hat.reshape(ntest, ntimes, nvelocity//2)\n","# Vtrain_hat = torch.sqrt(Vxtrain_hat.reshape(ntest, ntimes, nvelocity)**2 + Vytrain_hat.reshape(ntest, ntimes, nvelocity)**2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4nSqeY_otyJt"},"outputs":[],"source":["# Vxtest_hat = Vxtest_hat.reshape(ntest, ntimes, nvelocity)\n","# Vytest_hat = Vytest_hat.reshape(ntest, ntimes, nvelocity)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wBZstry7tqyb"},"outputs":[],"source":["# FOM vs POD RECONSTRUCTION (PLOTS)\n","\n","from utils.processdata import trajectories_with_sensors\n","\n","whichtrajectory = 2\n","whichtimes = np.arange(0, 200, 10)\n","\n","plotlist = [Vtest[whichtrajectory, whichtimes], Vtest_hat[whichtrajectory, whichtimes], Vtest[whichtrajectory, whichtimes] - Vtest_hat.numpy()[whichtrajectory, whichtimes]]\n","params_geo = MUtest[whichtrajectory, 0, 2:]\n","\n","plotlist = [Vtest[whichtrajectory, whichtimes], Vtest_hat[whichtrajectory, whichtimes], Vtest[whichtrajectory, whichtimes] - Vtest_hat.numpy()[whichtrajectory, whichtimes]]\n","\n","\n","# redefine plot_v on new triang\n","_, triang = update_coords_and_triang(params_geo)\n","def plot_v(v, triang = triang):\n","    plt.tricontourf(triang, v, cmap = cmap, levels = 200)\n","    plt.gca().set_aspect(\"equal\")\n","    add_zoom(zoom = 1.3)\n","\n","vmin = min(np.abs(plotlist[i]).min() for i in range(len(plotlist)))\n","vmax = max(np.abs(plotlist[i]).max() for i in range(len(plotlist)))\n","\n","trajectories_with_sensors(plotlist, plot_v, idx_sensors, sensors_coords_test[whichtrajectory].detach().cpu().numpy(), titles = (\"Velocity trajectory\", \"SHRED prediction\", \"Prediction error\"), figsize = (10, 5), vertical = False, save = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lSsvHLwFdAst"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jvdcusGKA7Np"},"outputs":[],"source":["# FOM vs SHRED PREDICTION (PLOTS)\n","\n","def trajectories_with_sensors(vts, params_geo, idx_sensors, titles = None):\n","    \"\"\"\n","    Trajectories with sensors\n","    Input: list of trajectories with dimension (ntimes, nstate), geometric parameters and and the selected sensor indices\n","    \"\"\"\n","\n","    # redefine plot_v on new triang\n","    coords, triang = update_coords_and_triang(params_geo)\n","    def plot_v(v, triang = triang):\n","        plt.tricontourf(triang, v, cmap = cmap, levels = 200)\n","        plt.gca().set_aspect(\"equal\")\n","        add_zoom(zoom = 1.3)\n","\n","    sensors_coordinates = coords[idx_sensors, :2]\n","\n","    for i in range(vts[0].shape[0]):\n","\n","        vmin = min(vts[j].abs().min() for j in range(len(vts)))\n","        vmax = max(vts[j].abs().max() for j in range(len(vts)))\n","\n","        plt.figure(figsize = (10, 5))\n","        for j in range(len(vts)):\n","            plot_v(vts[j][i])\n","            if j < len(vts)-1:\n","               for k in np.arange(nsensors):\n","                   plt.plot(sensors_coordinates[k, 0], sensors_coordinates[k, 1], 'o', mfc = 'magenta', mec = 'black', ms = 8, mew = 1.5)\n","            plt.xlim((-0.1,10.1))\n","            plt.title(titles[j])\n","            plt.axis('off')\n","\n","        display(plt.gcf())\n","        plt.close()\n","        clc(wait=True)\n","\n","whichtrajectory = 0\n","whichtimes = np.arange(180, 200)\n","\n","plotlist = [Vtest[whichtrajectory, whichtimes], Vtest_hat.numpy()[whichtrajectory, whichtimes], Vtest[whichtrajectory, whichtimes] - Vtest_hat.numpy()[whichtrajectory, whichtimes]]\n","\n","trajectories_with_sensors(plotlist, MUtest[whichtrajectory, 0, 2:], idx_sensors, titles = (\"Velocity trajectory\", \"SHRED prediction\", \"Prediction error\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NFFbSWtFIvA0"},"outputs":[],"source":["type(Vtest_hat)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w4Gl8OYRA7Nq"},"outputs":[],"source":["# PARAMETER vs SHRED PREDICTION (PLOT)\n","\n","times = np.arange(0, T + float(dt), float(dt))\n","\n","def trajectory_parameter_estimation(MU, MU_hat, title = None):\n","    \"\"\"\n","    Trajectory for parameter estimation in time\n","    Input: ground truth trajectory and corresponding estimate\n","    \"\"\"\n","\n","    plt.figure(figsize = (7,5))\n","    for i in range(1, MU.shape[0] + 1):\n","        plt.plot(times[:i], MU[:i], color = \"black\", linewidth = 2, label = r\"$\\alpha_{in}$\")\n","        plt.plot(times[:i], MU_hat[:i], color = \"magenta\", linewidth = 2, label = r\"$\\hat {\\alpha}_{in}$\")\n","        plt.plot(times[i-1], MU[i-1], 'o', color = \"black\")\n","        plt.plot(times[i-1], MU_hat[i-1], 'o', color = \"magenta\")\n","        if i < MU.shape[0]:\n","            plt.vlines(times[i-1], -2,  2, color = \"lightgray\")\n","        plt.grid()\n","        plt.xlabel(\"Time $t$\", fontsize = 15)\n","        plt.xticks(fontsize = 13)\n","        plt.yticks(fontsize = 13)\n","        plt.xlim((times[0]-0.5, times[-1]+0.55))\n","        plt.ylim((-1.2, 1.2))\n","        plt.legend(fontsize = 15, loc='upper left', handlelength = 1.0, shadow = True)\n","        plt.title(title, fontsize = 13)\n","        display(plt.gcf())\n","        plt.close()\n","        clc(wait=True)\n","\n","whichtrajectory = 0\n","\n","trajectory_parameter_estimation(MUtest[whichtrajectory,:,0], alpha_in_test_hat[whichtrajectory], title = (\"Parameter estimation\"))"]},{"cell_type":"markdown","metadata":{"id":"krAm5toDUvQs"},"source":["### Creazione timeseries coordinate sensori"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7vtgAU28VF0C"},"outputs":[],"source":["# # EXTRACT SENSOR DATA (SKIP THIS CELL IF DATA ALREADY AVAILABLE)\n","# idx_sensors = np.random.choice(nvelocity, size = nsensors, replace = False)\n","\n","# sensors_data_train = Vxtrain[:,:,idx_sensors]\n","# sensors_data_valid = Vxvalid[:,:,idx_sensors]\n","# sensors_data_test = Vxtest[:,:,idx_sensors]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2N_3exxQXBU9"},"outputs":[],"source":["# # va bene solo per posizioni non trainabili (di fatto inutile)\n","\n","# sensors_coords_train = np.tile(np.expand_dims(XY[idx_train][:, idx_sensors], 1), reps = (1, ntimes, 1, 1))\n","# sensors_data_train = np.concatenate((sensors_coords_train, np.expand_dims(sensors_data_train, -1)), -1).reshape((len(idx_train), ntimes, -1))\n","# sensors_data_train = torch.from_numpy(sensors_data_train).to(torch.float).to(device)\n","\n","# sensors_coords_valid = np.tile(np.expand_dims(XY[idx_valid][:, idx_sensors], 1), reps = (1, ntimes, 1, 1))\n","# sensors_data_valid = np.concatenate((sensors_coords_valid, np.expand_dims(sensors_data_valid, -1)), -1).reshape((len(idx_valid), ntimes, -1))\n","# sensors_data_valid = torch.from_numpy(sensors_data_valid).to(torch.float).to(device)\n","\n","# sensors_coords_test = np.tile(np.expand_dims(XY[idx_test][:, idx_sensors], 1), reps = (1, ntimes, 1, 1))\n","# sensors_data_test = np.concatenate((sensors_coords_test, np.expand_dims(sensors_data_test, -1)), -1).reshape((len(idx_test), ntimes, -1))\n","# sensors_data_test = torch.from_numpy(sensors_data_test).to(torch.float).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mC-hz-vXgoeG"},"outputs":[],"source":["# del  sensors_coords_train, sensors_coords_valid, sensors_coords_test, sensors_data_train, sensors_data_valid, sensors_data_test"]}],"metadata":{"colab":{"collapsed_sections":["02yGSI8pdVlq","5Ob_XRuhcYLF","ZiAJPCEOW-TG","NixfVmQJ8BBh","ugYJ5O9lwUI2","krAm5toDUvQs","8d3yX9zMowmN","w89SUJX78BBk","2XkhzZ9Owr2i","oz9Gu0urI6B6","fEn9S8NaFzh7","wThwpcxT7Po5"],"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}